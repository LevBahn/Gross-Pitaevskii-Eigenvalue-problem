{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efbqfOtOZasn",
      "metadata": {
        "id": "efbqfOtOZasn"
      },
      "source": [
        "This notebook implements supervised weights for approximating the solution to the one-dimensional Gross-Pitavskii equation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3nYdXyrr-Z7h",
      "metadata": {
        "id": "3nYdXyrr-Z7h"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pytorch-optimizer\n",
        "!git clone https://github.com/facebookresearch/optimizers.git\n",
        "%cd optimizers\n",
        "!pip install .\n",
        "%cd .."
      ],
      "metadata": {
        "id": "AMbBG2cmozTe"
      },
      "id": "AMbBG2cmozTe",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "BMnx60Sj-Z7j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMnx60Sj-Z7j",
        "outputId": "2d4d4888-f9c4-4f7d-8d89-d06924b63ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.autograd import grad\n",
        "from scipy.special import hermite\n",
        "# from adabelief_pytorch import AdaBelief\n",
        "from pytorch_optimizer import QHAdam, AdaHessian, Ranger21, SophiaH, Shampoo\n",
        "#from distributed_shampoo import AdamGraftingConfig, DistributedShampoo, DefaultEigenvalueCorrectedShampooConfig\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import torch.nn.utils\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.special import airy, gamma as gamma_func\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hglIb1ul-Z7n",
      "metadata": {
        "id": "hglIb1ul-Z7n"
      },
      "source": [
        "# Physics Informed Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "NFVJh4jB-Z7o",
      "metadata": {
        "id": "NFVJh4jB-Z7o"
      },
      "outputs": [],
      "source": [
        "class GrossPitaevskiiPINN(nn.Module):\n",
        "    \"\"\"\n",
        "    Physics-Informed Neural Network (PINN) for solving the 1D Gross-Pitaevskii Equation\n",
        "    with a gravitational trap potential.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layers, hbar=1.0, m=1.0, mode=0, gamma=1.0):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        layers : list of int\n",
        "            Neural network architecture, each entry defines the number of neurons in that layer.\n",
        "        hbar : float, optional\n",
        "            Reduced Planck's constant (default is 1.0).\n",
        "        m : float, optional\n",
        "            Mass of the particle (default is 1.0).\n",
        "        mode : int, optional\n",
        "            Mode number (default is 0).\n",
        "        gamma : float, optional\n",
        "            Interaction strength parameter.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.network = self.build_network()\n",
        "        self.hbar = hbar  # Planck's constant, fixed\n",
        "        self.m = m  # Particle mass, fixed\n",
        "        self.mode = mode  # Mode number (n)\n",
        "        self.gamma = gamma  # Interaction strength parameter\n",
        "        self.g = 1.0  # Gravitational acceleration parameter\n",
        "\n",
        "    def build_network(self):\n",
        "        \"\"\"\n",
        "        Build the neural network with tanh activation functions between layers.\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            layers.append(nn.Linear(self.layers[i], self.layers[i + 1]))\n",
        "            if i < len(self.layers) - 2:\n",
        "                layers.append(nn.Tanh())\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def gravitational_solution(self, x, n):\n",
        "        \"\"\"\n",
        "        Compute the analytical solution for the gravitational trap for the linear case (gamma = 0).\n",
        "        Based on equations (28)-(31) from the paper.\n",
        "\n",
        "        For gravitational potential V(x) = mgx for x > 0 and infinity for x < 0.\n",
        "        The solutions involve Airy functions.\n",
        "        \"\"\"\n",
        "        # Convert to numpy for Airy function calculation\n",
        "        x_np = x.cpu().detach().numpy()\n",
        "\n",
        "        # Parameters for gravitational trap (equations 28-31 in the paper)\n",
        "        xi_n = self.get_airy_zeros(n + 1)[-1]  # Get the (n+1)th zero of the Airy function\n",
        "        l_0 = (self.hbar ** 2 / (2 * self.m ** 2 * self.g)) ** (1 / 3)  # Characteristic length\n",
        "\n",
        "        # Calculate xi = (x/l_0 - E_n/(m*g*l_0))\n",
        "        # Where E_n = -xi_n * m * g * l_0 is the energy of the nth state\n",
        "        xi = x_np / l_0 - xi_n\n",
        "\n",
        "        # Calculate the Airy function\n",
        "        Ai_vals = np.zeros_like(xi)\n",
        "        mask = x_np >= 0  # Only calculate for x >= 0 (where potential is finite)\n",
        "\n",
        "        # Get Airy function values where x >= 0\n",
        "        Ai_vals[mask] = airy(xi[mask])[0]\n",
        "\n",
        "        # Normalization factor (from paper equation 31)\n",
        "        # This is approximate and might need manual adjustment\n",
        "        norm_factor = 1.0 / (l_0 * (airy(xi_n)[1]) ** 2) ** (0.5)\n",
        "\n",
        "        # Convert back to tensor and apply normalization\n",
        "        solution = norm_factor * torch.tensor(Ai_vals, dtype=torch.float32).to(device)\n",
        "\n",
        "        # Set solution to zero for x < 0 (infinite potential barrier)\n",
        "        solution[x < 0] = 0.0\n",
        "\n",
        "        return solution\n",
        "\n",
        "    def get_airy_zeros(self, num_zeros):\n",
        "        \"\"\"\n",
        "        Get the first n zeros of the Airy function Ai(x).\n",
        "        These are the negative zeros in ascending order by absolute value.\n",
        "        \"\"\"\n",
        "        # Approximate values of the first several zeros of the Airy function\n",
        "        # These are more precise than what scipy.special.ai_zeros provides for the small n we need\n",
        "        airy_zeros = [\n",
        "            -2.33811, -4.08795, -5.52056, -6.78671, -7.94413,\n",
        "            -9.02265, -10.0401, -11.0085, -11.9361, -12.8288,\n",
        "            -13.6915, -14.5272, -15.3394, -16.1307, -16.9039\n",
        "        ]\n",
        "        return np.array(airy_zeros[:num_zeros])\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass through the neural network.\n",
        "        \"\"\"\n",
        "        return self.network(inputs)\n",
        "\n",
        "    def get_complete_solution(self, x, perturbation, mode=None):\n",
        "        \"\"\"\n",
        "        Get the complete solution by combining the base gravitational solution with\n",
        "        the neural network perturbation.\n",
        "        \"\"\"\n",
        "        if mode is None:\n",
        "            mode = self.mode\n",
        "        base_solution = self.gravitational_solution(x, mode)\n",
        "        return base_solution + perturbation\n",
        "\n",
        "    def compute_potential(self, x, potential_type=\"gravitational\", **kwargs):\n",
        "        \"\"\"\n",
        "        Compute potential function for the 1D domain.\n",
        "        \"\"\"\n",
        "        if potential_type == \"gravitational\":\n",
        "            g = kwargs.get('g', self.g)  # Gravitational acceleration\n",
        "            # V(x) = mgx for x >= 0, and infinity (practically a large value) for x < 0\n",
        "            V = torch.zeros_like(x)\n",
        "            mask_positive = (x >= 0)\n",
        "            mask_negative = (x < 0)\n",
        "\n",
        "            V[mask_positive] = self.m * g * x[mask_positive]\n",
        "            V[mask_negative] = 1e6  # Very large value to approximate infinity\n",
        "\n",
        "        elif potential_type == \"harmonic\":\n",
        "            omega = kwargs.get('omega', 1.0)  # Frequency for harmonic potential\n",
        "            V = 0.5 * omega ** 2 * x ** 2\n",
        "        elif potential_type == \"gaussian\":\n",
        "            a = kwargs.get('a', 0.0)  # Center of the Gaussian\n",
        "            V = torch.exp(-(x - a) ** 2)\n",
        "        elif potential_type == \"periodic\":\n",
        "            V0 = kwargs.get('V0', 1.0)  # Depth of the potential\n",
        "            k = kwargs.get('k', 2 * np.pi / 5.0)  # Wave number for periodic potential\n",
        "            V = V0 * torch.cos(k * x) ** 2\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown potential type: {potential_type}\")\n",
        "        return V\n",
        "\n",
        "    def pde_loss(self, inputs, predictions, gamma, potential_type=\"gravitational\", precomputed_potential=None):\n",
        "        \"\"\"\n",
        "        Compute the PDE loss for the Gross-Pitaevskii equation.\n",
        "        μψ = -1/2 ∇²ψ + Vψ + γ|ψ|²ψ\n",
        "        \"\"\"\n",
        "        # Get the complete solution (base + perturbation)\n",
        "        u = self.get_complete_solution(inputs, predictions)\n",
        "\n",
        "        # Compute derivatives with respect to x\n",
        "        u_x = torch.autograd.grad(\n",
        "            outputs=u,\n",
        "            inputs=inputs,\n",
        "            grad_outputs=torch.ones_like(u),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0]\n",
        "\n",
        "        u_xx = torch.autograd.grad(\n",
        "            outputs=u_x,\n",
        "            inputs=inputs,\n",
        "            grad_outputs=torch.ones_like(u_x),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0]\n",
        "\n",
        "        # Compute potential\n",
        "        if precomputed_potential is not None:\n",
        "            V = precomputed_potential\n",
        "        else:\n",
        "            V = self.compute_potential(inputs, potential_type)\n",
        "\n",
        "        # Calculate chemical potential\n",
        "        kinetic = -0.5 * u_xx\n",
        "        potential = V * u\n",
        "        interaction = gamma * u ** 3\n",
        "\n",
        "        numerator = torch.mean(u * (kinetic + potential + interaction))\n",
        "        denominator = torch.mean(u ** 2)\n",
        "        lambda_pde = numerator / denominator\n",
        "\n",
        "        # Residual of the 1D Gross-Pitaevskii equation\n",
        "        pde_residual = kinetic + potential + interaction - lambda_pde * u\n",
        "\n",
        "        # PDE loss (mean squared residual)\n",
        "        pde_loss = torch.mean(pde_residual ** 2)\n",
        "\n",
        "        return pde_loss, pde_residual, lambda_pde, u\n",
        "\n",
        "    def riesz_loss(self, inputs, predictions, gamma, potential_type=\"gravitational\", precomputed_potential=None):\n",
        "        \"\"\"\n",
        "        Compute the Riesz energy loss for the Gross-Pitaevskii equation.\n",
        "        E[ψ] = ∫[|∇ψ|²/2 + V|ψ|² + γ|ψ|⁴/2]dx\n",
        "\n",
        "        This corresponds to Algorithm 2 in the paper at https://arxiv.org/pdf/1208.2123\n",
        "        \"\"\"\n",
        "        # Get the complete solution (base + perturbation)\n",
        "        u = self.get_complete_solution(inputs, predictions)\n",
        "\n",
        "        # Ensure inputs require gradients for autograd\n",
        "        if not inputs.requires_grad:\n",
        "            inputs = inputs.clone().detach().requires_grad_(True)\n",
        "\n",
        "        # Compute derivative with respect to x\n",
        "        u_x = torch.autograd.grad(\n",
        "            outputs=u,\n",
        "            inputs=inputs,\n",
        "            grad_outputs=torch.ones_like(u),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0]\n",
        "\n",
        "        # Calculate normalization factor for proper integration\n",
        "        dx = inputs[1] - inputs[0]  # Grid spacing\n",
        "        norm_factor = torch.sum(u ** 2) * dx\n",
        "\n",
        "        # Kinetic energy term: |∇ψ|²/2 with proper normalization\n",
        "        kinetic_term = 0.5 * torch.sum(u_x ** 2) * dx / norm_factor\n",
        "\n",
        "        # Potential term: V|ψ|² with proper normalization\n",
        "        if precomputed_potential is not None:\n",
        "            V = precomputed_potential\n",
        "        else:\n",
        "            V = self.compute_potential(inputs, potential_type)\n",
        "        potential_term = torch.sum(V * u ** 2) * dx / norm_factor\n",
        "\n",
        "        # Interaction term: γ|ψ|⁴/2 with proper normalization\n",
        "        interaction_term = 0.5 * gamma * torch.sum(u ** 4) * dx / norm_factor\n",
        "\n",
        "        # Total Riesz energy functional\n",
        "        riesz_energy = kinetic_term + potential_term + interaction_term\n",
        "\n",
        "        # Calculate chemical potential using variational approach\n",
        "        lambda_riesz = riesz_energy\n",
        "\n",
        "        return riesz_energy, lambda_riesz, u\n",
        "\n",
        "    def boundary_loss(self, boundary_points, boundary_values):\n",
        "        \"\"\"\n",
        "        Compute the boundary loss for the boundary conditions.\n",
        "        For gravitational trap, we need to enforce ψ(x) = 0 for x < 0.\n",
        "        \"\"\"\n",
        "        u_pred = self.forward(boundary_points)\n",
        "        full_u = self.get_complete_solution(boundary_points, u_pred)\n",
        "        return torch.mean((full_u - boundary_values) ** 2)\n",
        "\n",
        "    def negative_domain_loss(self, x):\n",
        "        \"\"\"\n",
        "        Enforce zero wavefunction in the negative domain (x < 0) for gravitational trap.\n",
        "        \"\"\"\n",
        "        # Select points where x < 0\n",
        "        mask = x < 0\n",
        "        if not torch.any(mask):\n",
        "            return torch.tensor(0.0, device=device)\n",
        "\n",
        "        x_neg = x[mask]\n",
        "        u_pred = self.forward(x_neg)\n",
        "        full_u = self.get_complete_solution(x_neg, u_pred)\n",
        "\n",
        "        # Penalize any non-zero values in the negative domain\n",
        "        return torch.mean(full_u ** 2)\n",
        "\n",
        "    def normalization_loss(self, u, dx):\n",
        "        \"\"\"\n",
        "        Compute normalization loss using proper numerical integration.\n",
        "        \"\"\"\n",
        "        integral = torch.sum(u ** 2) * dx\n",
        "        return (integral - 1.0) ** 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FzMOyXAj7jey",
      "metadata": {
        "id": "FzMOyXAj7jey"
      },
      "source": [
        "# Initialize Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "GyMrRGdE7lB2",
      "metadata": {
        "id": "GyMrRGdE7lB2"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    \"\"\"\n",
        "    Initialize the weights using Xavier uniform initialization.\n",
        "    \"\"\"\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AKKgTNHo24k4",
      "metadata": {
        "id": "AKKgTNHo24k4"
      },
      "source": [
        "# Train GPE Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1kAWdOgL26tv",
      "metadata": {
        "id": "1kAWdOgL26tv"
      },
      "outputs": [],
      "source": [
        "def train_gpe_model(gamma_values, modes, X_train, lb, ub, layers, epochs,\n",
        "                    potential_type='gravitational', lr=1e-3, verbose=True):\n",
        "    \"\"\"\n",
        "    Train the GPE model for different modes and gamma values.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    gamma_values : list of float\n",
        "        List of interaction strengths to train models for\n",
        "    modes : list of int\n",
        "        List of modes to train (0, 1, 2, 3, etc.)\n",
        "    X_train : numpy.ndarray\n",
        "        Training points array\n",
        "    lb, ub : float\n",
        "        Lower and upper boundaries of the domain\n",
        "    layers : list of int\n",
        "        Network architecture\n",
        "    epochs : int\n",
        "        Number of training epochs\n",
        "    potential_type : str\n",
        "        Type of potential ('gravitational', 'harmonic', etc.)\n",
        "    lr : float\n",
        "        Learning rate\n",
        "    verbose : bool\n",
        "        Whether to print training progress\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    tuple: (models_by_mode, mu_table)\n",
        "        Trained models organized by mode and gamma, and chemical potential values\n",
        "    \"\"\"\n",
        "    # Convert training data to tensors\n",
        "    dx = X_train[1, 0] - X_train[0, 0]  # Assuming uniform grid\n",
        "    X_tensor = torch.tensor(X_train, dtype=torch.float32, requires_grad=True).to(device)\n",
        "\n",
        "    # Create boundary conditions\n",
        "    # For gravitational trap, we need to enforce ψ(x) = 0 for x < 0\n",
        "    # and ψ(x) → 0 as x → ∞\n",
        "    boundary_points = torch.tensor([[lb], [0.0], [ub]], dtype=torch.float32).to(device)\n",
        "    boundary_values = torch.zeros((3, 1), dtype=torch.float32).to(device)\n",
        "\n",
        "    # Track models and chemical potentials\n",
        "    models_by_mode = {}\n",
        "    mu_table = {}\n",
        "\n",
        "    # Sort gamma values\n",
        "    gamma_values = sorted(gamma_values)\n",
        "\n",
        "    for mode in modes:\n",
        "        if verbose:\n",
        "            print(f\"\\n===== Training for mode {mode} =====\")\n",
        "\n",
        "        mu_logs = []\n",
        "        models_by_gamma = {}\n",
        "        prev_model = None\n",
        "\n",
        "        for gamma in gamma_values:\n",
        "            if verbose:\n",
        "                print(f\"\\nTraining for γ = {gamma:.2f}, mode = {mode}\")\n",
        "\n",
        "            # Initialize model for this mode and gamma\n",
        "            model = GrossPitaevskiiPINN(layers, mode=mode, gamma=gamma).to(device)\n",
        "\n",
        "            # If this isn't the first gamma value, initialize with previous model's weights\n",
        "            if prev_model is not None:\n",
        "                model.load_state_dict(prev_model.state_dict())\n",
        "            else:\n",
        "                # Use the advanced initialization that considers mode number\n",
        "                model.apply(lambda m: advanced_initialization(m, mode))\n",
        "\n",
        "            # Adam optimizer\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "            # Create scheduler to decrease learning rate during training\n",
        "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optimizer, mode='min', factor=0.5, patience=100, min_lr=1e-5, verbose=verbose\n",
        "            )\n",
        "\n",
        "            # Pre-compute potential for efficiency\n",
        "            potential = model.compute_potential(X_tensor, potential_type=potential_type)\n",
        "\n",
        "            # Track learning history\n",
        "            lambda_history = []\n",
        "            loss_history = []\n",
        "            constraint_history = []\n",
        "\n",
        "            for epoch in range(epochs):\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                u_pred = model.forward(X_tensor)\n",
        "\n",
        "                # Calculate common constraint losses for all modes\n",
        "                boundary_loss = model.boundary_loss(boundary_points, boundary_values)\n",
        "\n",
        "                # For gravitational trap, enforce zero wavefunction for x < 0\n",
        "                negative_domain_loss = model.negative_domain_loss(X_tensor)\n",
        "\n",
        "                # Ensure proper normalization\n",
        "                norm_loss = model.normalization_loss(model.get_complete_solution(X_tensor, u_pred), dx)\n",
        "\n",
        "                # Combined constraint loss - the negative domain constraint is crucial for gravitational trap\n",
        "                constraint_loss = 10.0 * boundary_loss + 50.0 * negative_domain_loss + 20.0 * norm_loss\n",
        "\n",
        "                # Decide which loss to use based on mode\n",
        "                if mode == 0:\n",
        "                    # Use Riesz energy functional for mode 0 as specified in the paper (Algorithm 2)\n",
        "                    riesz_energy, lambda_value, full_u = model.riesz_loss(\n",
        "                        X_tensor, u_pred, gamma, potential_type, precomputed_potential=potential\n",
        "                    )\n",
        "\n",
        "                    # For mode 0, we want to minimize the energy while satisfying constraints\n",
        "                    physics_loss = riesz_energy\n",
        "                    loss_type = \"Riesz energy\"\n",
        "\n",
        "                    # Track the constraints separately for monitoring\n",
        "                    monitoring_loss = constraint_loss.item()\n",
        "                else:\n",
        "                    # Use PDE residual for other modes\n",
        "                    pde_loss, _, lambda_value, full_u = model.pde_loss(\n",
        "                        X_tensor, u_pred, gamma, potential_type, precomputed_potential=potential\n",
        "                    )\n",
        "                    physics_loss = pde_loss\n",
        "                    loss_type = \"PDE residual\"\n",
        "\n",
        "                    # For PDE residual, we do expect the residual to approach zero\n",
        "                    monitoring_loss = pde_loss.item()\n",
        "\n",
        "                # Total loss for optimization\n",
        "                total_loss = physics_loss + constraint_loss\n",
        "\n",
        "                # Backpropagate\n",
        "                total_loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
        "                optimizer.step()\n",
        "                scheduler.step(total_loss)\n",
        "\n",
        "                # Record history\n",
        "                if epoch % 100 == 0:\n",
        "                    lambda_history.append(lambda_value.item())\n",
        "                    loss_history.append(total_loss.item())\n",
        "                    constraint_history.append(monitoring_loss)\n",
        "\n",
        "                    if verbose and epoch % 500 == 0:\n",
        "                        if mode == 0:\n",
        "                            print(f\"Epoch {epoch}, {loss_type}: {physics_loss.item():.6f}, \"\n",
        "                                  f\"Constraints: {monitoring_loss:.6f}, μ: {lambda_value.item():.4f}\")\n",
        "                        else:\n",
        "                            print(\n",
        "                                f\"Epoch {epoch}, {loss_type}: {physics_loss.item():.6f}, μ: {lambda_value.item():.4f}\")\n",
        "\n",
        "            # Record final chemical potential and save model\n",
        "            final_mu = lambda_history[-1] if lambda_history else 0\n",
        "            mu_logs.append((gamma, final_mu))\n",
        "            models_by_gamma[gamma] = model\n",
        "\n",
        "            # Update prev_model for next gamma value\n",
        "            prev_model = model\n",
        "\n",
        "        # Store results for this mode\n",
        "        mu_table[mode] = mu_logs\n",
        "        models_by_mode[mode] = models_by_gamma\n",
        "\n",
        "    return models_by_mode, mu_table"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B0dvfxBOmPlR",
      "metadata": {
        "id": "B0dvfxBOmPlR"
      },
      "source": [
        "# Plot Wavefunction Densities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "FXsGZVhYmS1t",
      "metadata": {
        "id": "FXsGZVhYmS1t"
      },
      "outputs": [],
      "source": [
        "def plot_wavefunction_densities(models_by_mode, X_test, gamma_values, modes, save_dir=\"plots_gravitational\"):\n",
        "    \"\"\"\n",
        "    Plot wavefunction densities for different modes and gamma values.\n",
        "    Specially formatted for the gravitational trap to match Figure 7 in the paper.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Generate individual figures for each mode\n",
        "    for mode in modes:\n",
        "        if mode not in models_by_mode:\n",
        "            continue\n",
        "\n",
        "        # Create individual figure\n",
        "        plt.figure(figsize=(8, 6))\n",
        "\n",
        "        X_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "        dx = X_test[1, 0] - X_test[0, 0]  # Spatial step size\n",
        "\n",
        "        # Different line styles and colors - match the paper's color scheme\n",
        "        linestyles = ['-', '-', '-', '-', '-', '-', '-']\n",
        "        colors = ['k', 'b', 'r', 'g', 'm', 'c', 'orange', 'purple']\n",
        "\n",
        "        # Plot solutions for different gamma values\n",
        "        for j, gamma in enumerate(gamma_values):\n",
        "            if gamma not in models_by_mode[mode]:\n",
        "                continue\n",
        "\n",
        "            model = models_by_mode[mode][gamma]\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                u_pred = model.forward(X_tensor)\n",
        "                full_u = model.get_complete_solution(X_tensor, u_pred)\n",
        "                u_np = full_u.cpu().numpy().flatten()\n",
        "\n",
        "                # Normalization - ensure it's properly normalized for physical interpretation\n",
        "                u_np /= np.sqrt(np.sum(u_np ** 2) * dx)\n",
        "\n",
        "                # Enforce zero for x < 0 (infinite potential barrier)\n",
        "                u_np[X_test.flatten() < 0] = 0\n",
        "\n",
        "                # Plot wavefunction density\n",
        "                plt.plot(X_test.flatten(), u_np ** 2,\n",
        "                         linestyle=linestyles[j % len(linestyles)],\n",
        "                         color=colors[j % len(colors)],\n",
        "                         label=f\"γ={gamma:.1f}\")\n",
        "\n",
        "        # Configure individual figure to match the paper\n",
        "        plt.title(f\"Mode {mode} Wavefunction Density (Gravitational Trap)\", fontsize=14)\n",
        "        plt.xlabel(\"x\", fontsize=12)\n",
        "        plt.ylabel(\"|ψ(x)|²\", fontsize=12)\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.xlim(-2, 15)  # Adjusted range to focus on the positive domain\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, f\"grav_mode_{mode}_density.png\"), dpi=300)\n",
        "        plt.show()\n",
        "        #plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8P5eHv-QCQiE",
      "metadata": {
        "id": "8P5eHv-QCQiE"
      },
      "source": [
        "# Plot Combined Grid\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "wUq16rY6CUd9",
      "metadata": {
        "id": "wUq16rY6CUd9"
      },
      "outputs": [],
      "source": [
        "def plot_combined_grid(models_by_mode, X_test, gamma_values, modes, save_dir=\"plots_gravitational\"):\n",
        "    \"\"\"\n",
        "    Create a grid of subplots showing all modes.\n",
        "    Formatted to match Figure 7 in the paper.\n",
        "    \"\"\"\n",
        "    # Determine grid dimensions\n",
        "    n_modes = len(modes)\n",
        "    n_cols = min(4, n_modes)  # Max 4 columns\n",
        "    n_rows = (n_modes + n_cols - 1) // n_cols  # Ceiling division\n",
        "\n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows))\n",
        "\n",
        "    # Flatten axes if it's a 2D array\n",
        "    if n_rows > 1 or n_cols > 1:\n",
        "        axes = axes.flatten()\n",
        "    else:\n",
        "        axes = [axes]  # Make it iterable\n",
        "\n",
        "    X_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    dx = X_test[1, 0] - X_test[0, 0]  # Spatial step size\n",
        "\n",
        "    # Different line styles and colors - match paper's style\n",
        "    linestyles = ['-', '-', '-', '-', '-', '-']\n",
        "    colors = ['k', 'b', 'r', 'g', 'm', 'c', 'orange', 'purple']\n",
        "\n",
        "    # Plot each mode in its subplot\n",
        "    for i, mode in enumerate(modes):\n",
        "        if i >= len(axes) or mode not in models_by_mode:\n",
        "            continue\n",
        "\n",
        "        ax = axes[i]\n",
        "\n",
        "        # Plot solutions for different gamma values\n",
        "        for j, gamma in enumerate(gamma_values):\n",
        "            if gamma not in models_by_mode[mode]:\n",
        "                continue\n",
        "\n",
        "            model = models_by_mode[mode][gamma]\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                u_pred = model.forward(X_tensor)\n",
        "                full_u = model.get_complete_solution(X_tensor, u_pred)\n",
        "                u_np = full_u.cpu().numpy().flatten()\n",
        "\n",
        "                # Proper normalization\n",
        "                u_np /= np.sqrt(np.sum(u_np ** 2) * dx)\n",
        "\n",
        "                # Enforce zero for x < 0 (infinite potential barrier)\n",
        "                u_np[X_test.flatten() < 0] = 0\n",
        "\n",
        "                # Plot on the appropriate subplot\n",
        "                ax.plot(X_test.flatten(), u_np ** 2,\n",
        "                        linestyle=linestyles[j % len(linestyles)],\n",
        "                        color=colors[j % len(colors)],\n",
        "                        label=f\"γ={gamma:.1f}\")\n",
        "\n",
        "        # Configure the subplot to match the paper's style\n",
        "        ax.set_title(f\"Mode {mode}\", fontsize=12)\n",
        "        ax.set_xlabel(\"x\", fontsize=10)\n",
        "        ax.set_ylabel(\"|ψ(x)|²\", fontsize=10)\n",
        "        ax.grid(True)\n",
        "        ax.legend(fontsize=8)\n",
        "        ax.set_xlim(-2, 15)  # Focus on positive domain\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for i in range(len(modes), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    # Finalize and save combined figure\n",
        "    fig.suptitle(\"Wavefunction Densities for Gravitational Trap\", fontsize=16)\n",
        "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    fig.savefig(os.path.join(save_dir, \"grav_all_modes_combined.png\"), dpi=300)\n",
        "    plt.show()\n",
        "    #plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t7r4H0TVkyZb",
      "metadata": {
        "id": "t7r4H0TVkyZb"
      },
      "source": [
        "# Plot Mu versus Gamma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "__9usRWzk15-",
      "metadata": {
        "id": "__9usRWzk15-"
      },
      "outputs": [],
      "source": [
        "def plot_mu_vs_gamma(mu_table, modes, save_dir=\"plots_gravitational\"):\n",
        "    \"\"\"\n",
        "    Plot chemical potential vs. interaction strength for different modes.\n",
        "    Formatted to show the relationship for the gravitational trap.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Different markers for different modes\n",
        "    markers = ['o', 's', '^', 'v', 'D', 'x', '*', '+']\n",
        "    colors = ['k', 'b', 'r', 'g', 'm', 'c', 'orange', 'purple']\n",
        "\n",
        "    # Plot μ vs γ for each mode\n",
        "    for i, mode in enumerate(modes):\n",
        "        if mode not in mu_table:\n",
        "            continue\n",
        "\n",
        "        gamma_list, mu_list = zip(*mu_table[mode])\n",
        "        plt.plot(gamma_list, mu_list,\n",
        "                 marker=markers[i % len(markers)],\n",
        "                 color=colors[i % len(colors)],\n",
        "                 linestyle='-',\n",
        "                 label=f\"Mode {mode}\")\n",
        "\n",
        "    plt.xlabel(\"γ (Interaction Strength)\", fontsize=12)\n",
        "    plt.ylabel(\"μ (Chemical Potential)\", fontsize=12)\n",
        "    plt.title(\"Chemical Potential vs. Interaction Strength for Gravitational Trap\", fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_dir, \"grav_mu_vs_gamma_all_modes.png\"), dpi=300)\n",
        "    plt.show()\n",
        "    #plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mS-f4Mkzk4KD",
      "metadata": {
        "id": "mS-f4Mkzk4KD"
      },
      "source": [
        "# Advanced Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7XcQoQhFk78S",
      "metadata": {
        "id": "7XcQoQhFk78S"
      },
      "outputs": [],
      "source": [
        "def advanced_initialization(m, mode):\n",
        "    \"\"\"Initialize network weights with consideration of the mode number\"\"\"\n",
        "    if isinstance(m, nn.Linear):\n",
        "        # Use Xavier initialization but scale based on mode\n",
        "        gain = 1.0 / (1.0 + 0.1 * mode)  # Decrease gain for higher modes\n",
        "        nn.init.xavier_uniform_(m.weight, gain=gain)\n",
        "\n",
        "        # Initialize biases with small values\n",
        "        m.bias.data.fill_(0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7RmggB2e-Z7r",
      "metadata": {
        "id": "7RmggB2e-Z7r"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "js3eLQbPlIgm",
      "metadata": {
        "id": "js3eLQbPlIgm"
      },
      "outputs": [],
      "source": [
        "# Setup parameters\n",
        "lb, ub = -5, 20  # Domain boundaries adjusted for gravitational trap\n",
        "N_f = 5000  # Number of collocation points (increased for better resolution)\n",
        "epochs = 2001  # Increased epochs for better convergence\n",
        "layers = [1, 64, 64, 64, 1]  # Neural network architecture\n",
        "save_dir = \"plots_gravitational\"  # Define the output directory for plots\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Create uniform grid for training and testing\n",
        "X = np.linspace(lb, ub, N_f).reshape(-1, 1)\n",
        "X_test = np.linspace(lb, ub, 1000).reshape(-1, 1)  # Higher resolution for plotting\n",
        "\n",
        "# Gamma values from the paper\n",
        "gamma_values = [0.0, 10.0, 20.0, 30.0, 40.0, 50.0]\n",
        "\n",
        "# Include modes 0 through 7\n",
        "modes = [0, 1, 2, 3, 4, 5, 6, 7]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2AqQL8hWphaH",
      "metadata": {
        "id": "2AqQL8hWphaH"
      },
      "source": [
        "# Train Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7oJgKs8Ejr2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "7oJgKs8Ejr2d",
        "outputId": "9916ce06-660f-4cc4-c517-abf0f555461a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training for all modes and gamma values...\n",
            "\n",
            "===== Training for mode 0 =====\n",
            "\n",
            "Training for γ = 0.00, mode = 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1000 and 1x64)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-12ca2a4e2f2a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training for all modes and gamma values...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m models_by_mode, mu_table = train_gpe_model(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mgamma_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpotential_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gravitational'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-3d37f34dedf3>\u001b[0m in \u001b[0;36mtrain_gpe_model\u001b[0;34m(gamma_values, modes, X_train, lb, ub, layers, epochs, potential_type, lr, verbose)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;31m# For gravitational trap, enforce zero wavefunction for x < 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mnegative_domain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_domain_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;31m# Ensure proper normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f2c2bba53963>\u001b[0m in \u001b[0;36mnegative_domain_loss\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mx_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mu_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_neg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mfull_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_complete_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_neg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f2c2bba53963>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mForward\u001b[0m \u001b[0;32mpass\u001b[0m \u001b[0mthrough\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mneural\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_complete_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturbation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1000 and 1x64)"
          ]
        }
      ],
      "source": [
        "# Train models\n",
        "print(\"Starting training for all modes and gamma values...\")\n",
        "models_by_mode, mu_table = train_gpe_model(\n",
        "    gamma_values, modes, X, lb, ub, layers, epochs,\n",
        "    potential_type='gravitational', lr=1e-3, verbose=True\n",
        ")\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Wavefunction Densities"
      ],
      "metadata": {
        "id": "Xnn0moStmBpi"
      },
      "id": "Xnn0moStmBpi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot wavefunction densities for individual modes\n",
        "print(\"Generating individual mode plots...\")\n",
        "plot_wavefunction_densities(models_by_mode, X_test, gamma_values, modes)"
      ],
      "metadata": {
        "id": "01Y7-wjll8_O"
      },
      "id": "01Y7-wjll8_O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot μ vs γ for all modes"
      ],
      "metadata": {
        "id": "LXfz4CRRmFw9"
      },
      "id": "LXfz4CRRmFw9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot μ vs γ for all modes\n",
        "print(\"Generating chemical potential vs. gamma plot...\")\n",
        "plot_mu_vs_gamma(mu_table, modes)"
      ],
      "metadata": {
        "id": "Own6694dmHbl"
      },
      "id": "Own6694dmHbl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Also create a combined grid figure to show all modes\n",
        "plot_combined_grid(models_by_mode, X_test, gamma_values, modes, save_dir)"
      ],
      "metadata": {
        "id": "-rhmxgO_92Bj"
      },
      "id": "-rhmxgO_92Bj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}