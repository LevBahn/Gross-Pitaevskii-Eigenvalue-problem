{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efbqfOtOZasn",
      "metadata": {
        "id": "efbqfOtOZasn"
      },
      "source": [
        "This notebook implements supervised weights for approximating the solution to the one-dimensional Gross-Pitavskii equation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3nYdXyrr-Z7h",
      "metadata": {
        "id": "3nYdXyrr-Z7h"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not using distributed shampoo right now\n",
        "# %%capture\n",
        "# !pip install pytorch-optimizer\n",
        "# !git clone https://github.com/facebookresearch/optimizers.git\n",
        "# %cd optimizers\n",
        "# !pip install .\n",
        "# %cd ..\n",
        "%%capture\n",
        "!pip install scienceplots"
      ],
      "metadata": {
        "id": "AMbBG2cmozTe"
      },
      "id": "AMbBG2cmozTe",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "BMnx60Sj-Z7j",
      "metadata": {
        "id": "BMnx60Sj-Z7j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.special import airy, hermite\n",
        "#from distributed_shampoo import AdamGraftingConfig, DistributedShampoo\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import scienceplots\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.rcParams['text.usetex'] = False  # Disable LaTeX rendering\n",
        "\n",
        "plot_params = {\n",
        "    \"figure.dpi\": \"300\",\n",
        "    \"axes.labelsize\": 20,\n",
        "    \"axes.linewidth\": 1.5,\n",
        "    \"axes.titlesize\": 20,\n",
        "    \"xtick.labelsize\": 16,\n",
        "    \"ytick.labelsize\": 16,\n",
        "    \"legend.title_fontsize\": 14,\n",
        "    \"legend.fontsize\": 16,\n",
        "    \"xtick.major.size\": 3.5,\n",
        "    \"xtick.major.width\": 1.5,\n",
        "    \"xtick.minor.size\": 2.5,\n",
        "    \"xtick.minor.width\": 1.5,\n",
        "    \"ytick.major.size\": 3.5,\n",
        "    \"ytick.major.width\": 1.5,\n",
        "    \"ytick.minor.size\": 2.5,\n",
        "    \"ytick.minor.width\": 1.5,\n",
        "}\n",
        "\n",
        "plt.rcParams.update(plot_params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.special import airy, hermite\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import scienceplots\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.rcParams['text.usetex'] = False  # Disable LaTeX rendering\n",
        "\n",
        "plot_params = {\n",
        "    \"figure.dpi\": \"300\",\n",
        "    \"axes.labelsize\": 20,\n",
        "    \"axes.linewidth\": 1.5,\n",
        "    \"axes.titlesize\": 20,\n",
        "    \"xtick.labelsize\": 16,\n",
        "    \"ytick.labelsize\": 16,\n",
        "    \"legend.title_fontsize\": 14,\n",
        "    \"legend.fontsize\": 16,\n",
        "    \"xtick.major.size\": 3.5,\n",
        "    \"xtick.major.width\": 1.5,\n",
        "    \"xtick.minor.size\": 2.5,\n",
        "    \"xtick.minor.width\": 1.5,\n",
        "    \"ytick.major.size\": 3.5,\n",
        "    \"ytick.major.width\": 1.5,\n",
        "    \"ytick.minor.size\": 2.5,\n",
        "    \"ytick.minor.width\": 1.5,\n",
        "}\n",
        "\n",
        "plt.rcParams.update(plot_params)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(dim, dim)\n",
        "        self.lin2 = nn.Linear(dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = torch.tanh(self.lin1(x))\n",
        "        out = self.lin2(out)\n",
        "        return torch.tanh(out + identity)\n",
        "\n",
        "\n",
        "class GrossPitaevskiiPINN(nn.Module):\n",
        "    \"\"\"\n",
        "    Physics-Informed Neural Network (PINN) for solving the 1D Gross-Pitaevskii Equation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layers, hbar=1.0, m=1.0, mode=0, potential_type=\"harmonic\", gamma=1.0, L=1.0, g=1.0,\n",
        "                 use_residual=True):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        layers : list of int\n",
        "            Neural network architecture, each entry defines the number of neurons in that layer.\n",
        "        hbar : float, optional\n",
        "            Reduced Planck's constant (default is 1.0).\n",
        "        m : float, optional\n",
        "            Mass of the particle (default is 1.0).\n",
        "        mode : int, optional\n",
        "            Mode number (default is 0).\n",
        "        potential_type: str, optional\n",
        "            Type of potential (default is harmonic)\n",
        "        gamma : float, optional\n",
        "            Interaction strength parameter.\n",
        "        L : float, optional\n",
        "            Length of the box (default is 1.0).\n",
        "        g : float, optional\n",
        "            Gravitational acceleration parameter (default is 1.0).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.use_residual = use_residual\n",
        "        self.hbar = hbar  # Planck's constant, fixed\n",
        "        self.m = m  # Particle mass, fixed\n",
        "        self.mode = mode  # Mode number (n)\n",
        "        self.potential_type = potential_type  # Type of potential\n",
        "        self.gamma = gamma  # Interaction strength parameter\n",
        "        self.L = L  # Length of the box\n",
        "        self.g = g  # Gravitational acceleration parameter\n",
        "\n",
        "        # Now build the network after all attributes are set\n",
        "        self.network = self.build_network()\n",
        "\n",
        "    def build_network(self):\n",
        "        \"\"\"\n",
        "        Build the neural network with tanh activation functions and residual connections.\n",
        "        \"\"\"\n",
        "        if not self.use_residual:\n",
        "            # Original architecture without residual blocks\n",
        "            layers = []\n",
        "            for i in range(len(self.layers) - 1):\n",
        "                layers.append(nn.Linear(self.layers[i], self.layers[i + 1]))\n",
        "                if i < len(self.layers) - 2:\n",
        "                    layers.append(nn.Tanh())\n",
        "            return nn.Sequential(*layers)\n",
        "        else:\n",
        "            # New architecture with residual blocks\n",
        "            modules = []\n",
        "\n",
        "            # Input layer\n",
        "            input_dim = self.layers[0]\n",
        "            hidden_dim = self.layers[1]\n",
        "            modules.append(nn.Linear(input_dim, hidden_dim))\n",
        "            modules.append(nn.Tanh())\n",
        "\n",
        "            # Residual blocks in the middle layers\n",
        "            num_res_blocks = len(self.layers) - 3  # Subtract input, first hidden, and output\n",
        "            for _ in range(num_res_blocks):\n",
        "                modules.append(ResidualBlock(hidden_dim))\n",
        "\n",
        "            # Output layer\n",
        "            modules.append(nn.Linear(hidden_dim, self.layers[-1]))\n",
        "\n",
        "            return nn.Sequential(*modules)\n",
        "\n",
        "    def box_eigenfunction(self, x, n):\n",
        "        \"\"\"\n",
        "        Compute the analytic eigenfunction for a particle in a box.\n",
        "\n",
        "        For the linear case (gamma = 0), the solution is:\n",
        "        phi_n(x) = sqrt(2/L) * sin(n*pi*x/L)\n",
        "\n",
        "        This corresponds to equation (22) in the paper.\n",
        "        \"\"\"\n",
        "        # For mode 0, n=1 in the sine function per equation (22)\n",
        "        n_actual = n + 1  # Convert mode number to quantum number (n=0 → first excited state with n_actual=1)\n",
        "\n",
        "        # Normalization factor\n",
        "        norm_factor = torch.sqrt(torch.tensor(2.0 / self.L))\n",
        "\n",
        "        # Sine function with proper scaling\n",
        "        phi_n = norm_factor * torch.sin(n_actual * torch.pi * x / self.L)\n",
        "\n",
        "        return phi_n\n",
        "\n",
        "    def energy_eigenvalue(self, n):\n",
        "        \"\"\"\n",
        "        Compute the energy eigenvalue for mode n in a box potential.\n",
        "\n",
        "        E_n = (n²π²ħ²)/(2mL²)\n",
        "\n",
        "        With ħ=1 and m=1, this simplifies to:\n",
        "        E_n = (n²π²)/(2L²)\n",
        "        \"\"\"\n",
        "        return (n ** 2 * np.pi ** 2) / (2 * self.L ** 2)\n",
        "\n",
        "    def weighted_hermite(self, x, n):\n",
        "        \"\"\"\n",
        "        Compute the weighted Hermite polynomial solution for the linear case (gamma = 0).\n",
        "        \"\"\"\n",
        "        H_n = hermite(n)(x.cpu().detach().numpy())  # Hermite polynomial evaluated at x\n",
        "        norm_factor = (2 ** n * math.factorial(n) * np.sqrt(np.pi)) ** (-0.5)\n",
        "        weighted_hermite = norm_factor * torch.exp(-x ** 2 / 2) * torch.tensor(H_n, dtype=torch.float32).to(device)\n",
        "        return weighted_hermite\n",
        "\n",
        "    def airy_solution(self, x, n):\n",
        "        \"\"\"\n",
        "        Create gravitational trap eigenfunctions using Airy functions according to\n",
        "        equations (30-31) from the paper: Ψₙ(x) = Aₙ·Ai(x + xₙ)\n",
        "\n",
        "        Key fixes:\n",
        "        1. Use proper domain transformation: ξ = (mgx)^(1/3) * x for gravity well\n",
        "        2. Apply correct boundary conditions\n",
        "        3. Use exact Airy zeros from literature\n",
        "        \"\"\"\n",
        "        # Convert to numpy for calculation\n",
        "        x_np = x.detach().cpu().numpy()\n",
        "\n",
        "        # CRITICAL FIX: Transform to proper dimensionless coordinate\n",
        "        # For gravity well: ξ = (2mg/ℏ²)^(1/3) * x\n",
        "        # In dimensionless units with mg = 1, ℏ = 1, m = 1: ξ = (2)^(1/3) * x\n",
        "        xi_scale = (2.0) ** (1 / 3)\n",
        "        xi = xi_scale * x_np\n",
        "\n",
        "        # Initialize wavefunction array\n",
        "        psi = np.zeros_like(x_np)\n",
        "\n",
        "        # Airy function zeros (where Ai(z) = 0) - these are exact values\n",
        "        airy_zeros = [\n",
        "            -2.33810741, -4.08794944, -5.52055983, -6.78670809, -7.94413359,\n",
        "            -9.02265085, -10.0401743, -11.0085243, -11.9360157, -12.8287767\n",
        "        ]\n",
        "\n",
        "        # Get the nth zero\n",
        "        if n < len(airy_zeros):\n",
        "            z_n = airy_zeros[n]\n",
        "        else:\n",
        "            # Asymptotic approximation for higher modes\n",
        "            z_n = -(1.5 * np.pi * (n + 0.75)) ** (2 / 3)\n",
        "\n",
        "        # Only calculate for x >= 0 (gravity well domain)\n",
        "        pos_mask = (x_np >= 0)\n",
        "\n",
        "        if np.any(pos_mask):\n",
        "            # Calculate Ai(ξ + z_n) for positive x values\n",
        "            xi_pos = xi[pos_mask]\n",
        "            airy_vals = airy(xi_pos + z_n)[0]\n",
        "\n",
        "            # Apply proper normalization over the allowed domain\n",
        "            dx = float(x[1].detach() - x[0].detach()) if len(x) > 1 else 0.01\n",
        "\n",
        "            # Normalize only over x >= 0 domain\n",
        "            if len(airy_vals) > 0 and np.sum(airy_vals ** 2) > 0:\n",
        "                norm_factor = np.sqrt(np.sum(airy_vals ** 2) * dx)\n",
        "                if norm_factor > 1e-12:\n",
        "                    airy_vals = airy_vals / norm_factor\n",
        "\n",
        "            # Store result in positive domain\n",
        "            psi[pos_mask] = airy_vals\n",
        "\n",
        "        # x < 0 remains zero (infinite potential wall)\n",
        "        psi[x_np < 0] = 0.0\n",
        "\n",
        "        # Convert back to tensor\n",
        "        solution = torch.tensor(psi, dtype=torch.float32).to(device)\n",
        "        return solution\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass through the neural network.\n",
        "        \"\"\"\n",
        "        return self.network(inputs)\n",
        "\n",
        "    def get_complete_solution(self, x, perturbation, mode=None, potential_type=None):\n",
        "        \"\"\"\n",
        "        For gravity well, the NN should learn the FULL solution, not just perturbation\n",
        "        This follows Algorithm 2 more closely where the NN directly approximates the eigenfunction\n",
        "        \"\"\"\n",
        "        if mode is None:\n",
        "            mode = self.mode\n",
        "        if potential_type is None:\n",
        "            potential_type = self.potential_type\n",
        "\n",
        "        if potential_type == \"gravity well\":\n",
        "            # MAJOR FIX: For gravity well, use the NN output directly as the main solution\n",
        "            # Apply proper boundary condition through multiplication\n",
        "            x_squeezed = x.squeeze()\n",
        "\n",
        "            # Boundary condition: ψ(x) = 0 for x < 0, smooth transition at x = 0\n",
        "            boundary_factor = torch.where(\n",
        "                x_squeezed >= 0,\n",
        "                torch.ones_like(x_squeezed),\n",
        "                torch.zeros_like(x_squeezed)\n",
        "            ).unsqueeze(-1) if len(x.shape) > 1 else torch.where(\n",
        "                x_squeezed >= 0,\n",
        "                torch.ones_like(x_squeezed),\n",
        "                torch.zeros_like(x_squeezed)\n",
        "            )\n",
        "\n",
        "            # For x >= 0, use NN output with proper scaling for decay at infinity\n",
        "            # Add exponential decay factor for large x to enforce boundary condition at infinity\n",
        "            decay_factor = torch.exp(-0.1 * torch.relu(x_squeezed - 10))\n",
        "            if len(x.shape) > 1:\n",
        "                decay_factor = decay_factor.unsqueeze(-1)\n",
        "\n",
        "            return boundary_factor * decay_factor * perturbation\n",
        "\n",
        "        elif potential_type == \"harmonic\":\n",
        "            base_solution = self.weighted_hermite(x, mode)\n",
        "        else:\n",
        "            base_solution = self.box_eigenfunction(x, mode)\n",
        "\n",
        "        return base_solution + perturbation\n",
        "\n",
        "    def compute_potential(self, x, potential_type=\"harmonic\", **kwargs):\n",
        "        \"\"\"\n",
        "        Compute potential function for the 1D domain.\n",
        "        \"\"\"\n",
        "        if potential_type == \"harmonic\":\n",
        "            omega = kwargs.get('omega', 1.0)  # Frequency for harmonic potential\n",
        "            V = 0.5 * omega ** 2 * x ** 2\n",
        "        elif potential_type == \"gaussian\":\n",
        "            a = kwargs.get('a', 0.0)  # Center of the Gaussian\n",
        "            V = torch.exp(-(x - a) ** 2)\n",
        "        elif potential_type == \"box\":\n",
        "            # Infinite square well / box potential is zero inside the box\n",
        "            V = torch.zeros_like(x)\n",
        "        elif potential_type == \"gravity well\":\n",
        "            # FIXED: Proper gravity well potential V(x) = mgx for x >= 0\n",
        "            V = torch.zeros_like(x)\n",
        "            x_squeezed = x.squeeze() if len(x.shape) > 1 else x\n",
        "\n",
        "            # For x >= 0: V(x) = mgx (with mg = 1 in dimensionless units)\n",
        "            V = torch.where(\n",
        "                x_squeezed >= 0,\n",
        "                x_squeezed,  # Linear potential mgx\n",
        "                torch.full_like(x_squeezed, 1e8)  # Large value for x < 0\n",
        "            )\n",
        "\n",
        "            if len(x.shape) > 1:\n",
        "                V = V.unsqueeze(-1)\n",
        "\n",
        "            return V\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown potential type: {potential_type}\")\n",
        "        return V\n",
        "\n",
        "    def pde_loss(self, inputs, predictions, gamma, p, potential_type=\"harmonic\", precomputed_potential=None):\n",
        "        \"\"\"\n",
        "        Compute the PDE loss for the Gross-Pitaevskii equation.\n",
        "        μψ = -1/2 ∇²ψ + Vψ + γ|ψ|^p ψ\n",
        "        \"\"\"\n",
        "        # Get the complete solution\n",
        "        u = self.get_complete_solution(inputs, predictions)\n",
        "\n",
        "        # Ensure inputs require gradients\n",
        "        if not inputs.requires_grad:\n",
        "            inputs = inputs.clone().detach().requires_grad_(True)\n",
        "\n",
        "        # Compute derivatives with respect to x\n",
        "        u_x = torch.autograd.grad(\n",
        "            outputs=u,\n",
        "            inputs=inputs,\n",
        "            grad_outputs=torch.ones_like(u),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0]\n",
        "\n",
        "        u_xx = torch.autograd.grad(\n",
        "            outputs=u_x,\n",
        "            inputs=inputs,\n",
        "            grad_outputs=torch.ones_like(u_x),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0]\n",
        "\n",
        "        # Compute potential\n",
        "        if precomputed_potential is not None:\n",
        "            V = precomputed_potential\n",
        "        else:\n",
        "            V = self.compute_potential(inputs, potential_type)\n",
        "\n",
        "        # Calculate individual terms\n",
        "        kinetic = -0.5 * u_xx\n",
        "        potential = V * u\n",
        "\n",
        "        # Nonlinear interaction term: γ|ψ|^(p-1)ψ\n",
        "        interaction = gamma * (torch.abs(u) ** (p - 1)) * u\n",
        "\n",
        "        # FIXED: Chemical potential calculation for gravity well\n",
        "        if potential_type == \"gravity well\":\n",
        "            # Only integrate over the physical domain x >= 0\n",
        "            x_squeezed = inputs.squeeze() if len(inputs.shape) > 1 else inputs\n",
        "            pos_mask = (x_squeezed >= 0)\n",
        "\n",
        "            if torch.any(pos_mask):\n",
        "                u_pos = u[pos_mask] if len(u.shape) > 1 else u[pos_mask]\n",
        "                kinetic_pos = kinetic[pos_mask] if len(kinetic.shape) > 1 else kinetic[pos_mask]\n",
        "                potential_pos = potential[pos_mask] if len(potential.shape) > 1 else potential[pos_mask]\n",
        "                interaction_pos = interaction[pos_mask] if len(interaction.shape) > 1 else interaction[pos_mask]\n",
        "\n",
        "                numerator = torch.mean(u_pos * (kinetic_pos + potential_pos + interaction_pos))\n",
        "                denominator = torch.mean(u_pos ** 2)\n",
        "            else:\n",
        "                numerator = torch.tensor(0.0, device=device)\n",
        "                denominator = torch.tensor(1.0, device=device)\n",
        "        else:\n",
        "            # Standard calculation for other potentials\n",
        "            numerator = torch.mean(u * (kinetic + potential + interaction))\n",
        "            denominator = torch.mean(u ** 2)\n",
        "\n",
        "        # Chemical potential with regularization\n",
        "        lambda_pde = numerator / (denominator + 1e-12)\n",
        "\n",
        "        # Residual of the Gross-Pitaevskii equation\n",
        "        pde_residual = kinetic + potential + interaction - lambda_pde * u\n",
        "\n",
        "        # PDE loss (mean squared residual)\n",
        "        if potential_type == \"gravity well\":\n",
        "            # Only compute loss over physical domain\n",
        "            x_squeezed = inputs.squeeze() if len(inputs.shape) > 1 else inputs\n",
        "            pos_mask = (x_squeezed >= 0)\n",
        "            if torch.any(pos_mask):\n",
        "                residual_pos = pde_residual[pos_mask] if len(pde_residual.shape) > 1 else pde_residual[pos_mask]\n",
        "                pde_loss = torch.mean(residual_pos ** 2)\n",
        "            else:\n",
        "                pde_loss = torch.tensor(0.0, device=device)\n",
        "        else:\n",
        "            pde_loss = torch.mean(pde_residual ** 2)\n",
        "\n",
        "        return pde_loss, pde_residual, lambda_pde, u\n",
        "\n",
        "    def riesz_loss(self, inputs, predictions, gamma, p, potential_type=\"harmonic\", precomputed_potential=None):\n",
        "        \"\"\"\n",
        "        Compute the Riesz energy loss for the Gross-Pitaevskii equation.\n",
        "        E[ψ] = ∫[|∇ψ|²/2 + V|ψ|² + γ|ψ|^(p+1)/(p+1)]dx\n",
        "        \"\"\"\n",
        "        # Get the complete solution\n",
        "        u = self.get_complete_solution(inputs, predictions)\n",
        "\n",
        "        # Ensure inputs require gradients for autograd\n",
        "        if not inputs.requires_grad:\n",
        "            inputs = inputs.clone().detach().requires_grad_(True)\n",
        "\n",
        "        # Compute derivative with respect to x\n",
        "        u_x = torch.autograd.grad(\n",
        "            outputs=u,\n",
        "            inputs=inputs,\n",
        "            grad_outputs=torch.ones_like(u),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0]\n",
        "\n",
        "        # Calculate grid spacing\n",
        "        dx = inputs[1] - inputs[0] if len(inputs) > 1 else torch.tensor(0.01, device=device)\n",
        "\n",
        "        # Compute potential\n",
        "        if precomputed_potential is not None:\n",
        "            V = precomputed_potential\n",
        "        else:\n",
        "            V = self.compute_potential(inputs, potential_type)\n",
        "\n",
        "        # FIXED: For gravity well, only integrate over x >= 0\n",
        "        if potential_type == \"gravity well\":\n",
        "            x_squeezed = inputs.squeeze() if len(inputs.shape) > 1 else inputs\n",
        "            pos_mask = (x_squeezed >= 0)\n",
        "\n",
        "            if torch.any(pos_mask):\n",
        "                u_pos = u[pos_mask] if len(u.shape) > 1 else u[pos_mask]\n",
        "                u_x_pos = u_x[pos_mask] if len(u_x.shape) > 1 else u_x[pos_mask]\n",
        "                V_pos = V[pos_mask] if len(V.shape) > 1 else V[pos_mask]\n",
        "\n",
        "                # Normalization over positive domain only\n",
        "                norm_factor = torch.sum(u_pos ** 2) * dx + 1e-12\n",
        "\n",
        "                # Energy terms over positive domain\n",
        "                kinetic_term = 0.5 * torch.sum(u_x_pos ** 2) * dx / norm_factor\n",
        "                potential_term = torch.sum(V_pos * u_pos ** 2) * dx / norm_factor\n",
        "                interaction_term = (gamma / (p + 1)) * torch.sum(torch.abs(u_pos) ** (p + 1)) * dx / norm_factor\n",
        "            else:\n",
        "                kinetic_term = torch.tensor(0.0, device=device)\n",
        "                potential_term = torch.tensor(0.0, device=device)\n",
        "                interaction_term = torch.tensor(0.0, device=device)\n",
        "        else:\n",
        "            # Standard calculation for other potentials\n",
        "            norm_factor = torch.sum(u ** 2) * dx + 1e-12\n",
        "            kinetic_term = 0.5 * torch.sum(u_x ** 2) * dx / norm_factor\n",
        "            potential_term = torch.sum(V * u ** 2) * dx / norm_factor\n",
        "            interaction_term = (gamma / (p + 1)) * torch.sum(torch.abs(u) ** (p + 1)) * dx / norm_factor\n",
        "\n",
        "        # Total Riesz energy functional\n",
        "        riesz_energy = kinetic_term + potential_term + interaction_term\n",
        "\n",
        "        # Calculate chemical potential (energy eigenvalue)\n",
        "        lambda_riesz = riesz_energy\n",
        "\n",
        "        return riesz_energy, lambda_riesz, u\n",
        "\n",
        "    def boundary_loss(self, boundary_points, boundary_values):\n",
        "        \"\"\"\n",
        "        Compute the boundary loss for the boundary conditions.\n",
        "        \"\"\"\n",
        "        u_pred = self.forward(boundary_points)\n",
        "        full_u = self.get_complete_solution(boundary_points, u_pred)\n",
        "        return torch.mean((full_u - boundary_values) ** 2)\n",
        "\n",
        "    def boundary_loss_gravity_well(self, x):\n",
        "        \"\"\"\n",
        "        Compute boundary loss for gravity well with proper enforcement\n",
        "        \"\"\"\n",
        "        u_pred = self.forward(x)\n",
        "        full_u = self.get_complete_solution(x, u_pred)\n",
        "\n",
        "        x_squeezed = x.squeeze() if len(x.shape) > 1 else x\n",
        "\n",
        "        # Strong enforcement for x < 0: ψ(x) = 0\n",
        "        neg_mask = x_squeezed < 0\n",
        "        neg_loss = torch.mean(full_u[neg_mask] ** 2) if torch.any(neg_mask) else torch.tensor(0.0, device=device)\n",
        "\n",
        "        # Boundary condition at x = 0: should be continuous but can be non-zero\n",
        "        zero_mask = torch.abs(x_squeezed) < 0.05\n",
        "        # Don't enforce ψ(0) = 0 too strongly, as this depends on the mode\n",
        "        zero_loss = 0.1 * torch.mean(full_u[zero_mask] ** 2) if torch.any(zero_mask) else torch.tensor(0.0,\n",
        "                                                                                                       device=device)\n",
        "\n",
        "        # Decay condition for large x\n",
        "        far_mask = x_squeezed > 15\n",
        "        far_loss = torch.mean(full_u[far_mask] ** 2) if torch.any(far_mask) else torch.tensor(0.0, device=device)\n",
        "\n",
        "        return 1000.0 * neg_loss + zero_loss + 10.0 * far_loss\n",
        "\n",
        "    def symmetry_loss(self, collocation_points, potential_type=None):\n",
        "        \"\"\"\n",
        "        For gravity well, no symmetry constraints should be applied\n",
        "        \"\"\"\n",
        "        if potential_type is None:\n",
        "            potential_type = self.potential_type\n",
        "\n",
        "        # For gravity well, return zero since there's no symmetry\n",
        "        if potential_type == \"gravity well\":\n",
        "            return torch.tensor(0.0, device=device)\n",
        "\n",
        "        # Original symmetry loss for other potentials\n",
        "        if potential_type == \"box\":\n",
        "            L = self.L\n",
        "            x_reflected = L - collocation_points\n",
        "        else:\n",
        "            x_reflected = -collocation_points\n",
        "\n",
        "        u_pred_original = self.forward(collocation_points)\n",
        "        u_full_original = self.get_complete_solution(collocation_points, u_pred_original, potential_type=potential_type)\n",
        "\n",
        "        u_pred_reflected = self.forward(x_reflected)\n",
        "        u_full_reflected = self.get_complete_solution(x_reflected, u_pred_reflected, potential_type=potential_type)\n",
        "\n",
        "        if self.mode % 2 == 1:\n",
        "            sym_loss = torch.mean((u_full_original + u_full_reflected) ** 2)\n",
        "        else:\n",
        "            sym_loss = torch.mean((u_full_original - u_full_reflected) ** 2)\n",
        "\n",
        "        return sym_loss\n",
        "\n",
        "    def normalization_loss(self, u, dx, potential_type=None):\n",
        "        \"\"\"\n",
        "        Compute normalization loss with proper domain handling\n",
        "        \"\"\"\n",
        "        if potential_type is None:\n",
        "            potential_type = self.potential_type\n",
        "\n",
        "        if potential_type == \"gravity well\":\n",
        "            # This will be handled in the training loop with proper masking\n",
        "            pass\n",
        "\n",
        "        integral = torch.sum(u ** 2) * dx\n",
        "        return (integral - 1.0) ** 2\n",
        "\n",
        "\n",
        "# FIXED training function with better hyperparameters for gravity well\n",
        "def train_gpe_model(gamma_values, modes, p, X_train, lb, ub, layers, epochs,\n",
        "                    potential_type='harmonic', lr=1e-3, verbose=True):\n",
        "    \"\"\"\n",
        "    Train the GPE model for different modes and gamma values.\n",
        "\n",
        "    IMPROVEMENTS:\n",
        "    - Better learning rate scheduling for gravity well\n",
        "    - Improved loss weighting\n",
        "    - Better initialization\n",
        "    \"\"\"\n",
        "    # Convert training data to tensors\n",
        "    dx = X_train[1, 0] - X_train[0, 0]  # Assuming uniform grid\n",
        "    X_tensor = torch.tensor(X_train, dtype=torch.float32, requires_grad=True).to(device)\n",
        "\n",
        "    # Create boundary conditions\n",
        "    if potential_type == \"gravity well\":\n",
        "        L = ub\n",
        "        # More boundary points for gravity well\n",
        "        boundary_points = torch.tensor([lb, -2.0, -1.0, -0.5, 0.0, 0.5], dtype=torch.float32).reshape(-1, 1).to(device)\n",
        "    else:\n",
        "        L = ub\n",
        "        boundary_points = torch.tensor([[lb], [ub]], dtype=torch.float32).to(device)\n",
        "        boundary_values = torch.zeros((2, 1), dtype=torch.float32).to(device)\n",
        "\n",
        "    # Track models, chemical potentials, and training history\n",
        "    models_by_mode = {}\n",
        "    mu_table = {}\n",
        "    training_history = {}\n",
        "\n",
        "    # Sort gamma values\n",
        "    gamma_values = sorted(gamma_values)\n",
        "\n",
        "    # Precompute potential for the entire grid\n",
        "    temp_model = GrossPitaevskiiPINN(layers, potential_type=potential_type).to(device)\n",
        "    precomputed_potential = temp_model.compute_potential(X_tensor, potential_type).detach()\n",
        "\n",
        "    for mode in modes:\n",
        "        if verbose:\n",
        "            print(f\"\\n===== Training for mode {mode} =====\")\n",
        "\n",
        "        mu_logs = []\n",
        "        models_by_gamma = {}\n",
        "        history_by_gamma = {}\n",
        "        prev_model = None\n",
        "\n",
        "        for gamma in gamma_values:\n",
        "            if verbose:\n",
        "                print(\n",
        "                    f\"\\nTraining for γ = {gamma:.2f}, mode = {mode}, nonlinearity p = {p}, potential = {potential_type}\")\n",
        "\n",
        "            # Initialize model for this mode and gamma\n",
        "            model = GrossPitaevskiiPINN(layers, mode=mode, gamma=gamma, L=L, potential_type=potential_type).to(device)\n",
        "\n",
        "            # Better initialization for gravity well\n",
        "            if potential_type == \"gravity well\":\n",
        "                model.apply(lambda m: gravity_well_initialization(m, mode))\n",
        "            else:\n",
        "                if prev_model is not None:\n",
        "                    model.load_state_dict(prev_model.state_dict())\n",
        "                else:\n",
        "                    model.apply(lambda m: advanced_initialization(m, mode))\n",
        "\n",
        "            # Adaptive learning rate for gravity well\n",
        "            if potential_type == \"gravity well\":\n",
        "                initial_lr = 5e-4  # Lower initial learning rate\n",
        "            else:\n",
        "                initial_lr = lr\n",
        "\n",
        "            # Adam optimizer\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, weight_decay=1e-6)\n",
        "\n",
        "            # Better scheduler for gravity well\n",
        "            if potential_type == \"gravity well\":\n",
        "                scheduler = CosineAnnealingWarmRestarts(\n",
        "                    optimizer, T_0=500, T_mult=1, eta_min=1e-7\n",
        "                )\n",
        "            else:\n",
        "                scheduler = CosineAnnealingWarmRestarts(\n",
        "                    optimizer, T_0=200, T_mult=2, eta_min=1e-6\n",
        "                )\n",
        "\n",
        "            # Track learning history\n",
        "            lambda_history = []\n",
        "            loss_history = []\n",
        "            constraint_history = []\n",
        "\n",
        "            for epoch in range(epochs):\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                u_pred = model.forward(X_tensor)\n",
        "\n",
        "                # Calculate constraint losses with better weighting for gravity well\n",
        "                if potential_type == \"gravity well\":\n",
        "                    boundary_loss = model.boundary_loss_gravity_well(X_tensor)\n",
        "\n",
        "                    # Get the full solution for normalization\n",
        "                    full_u = model.get_complete_solution(X_tensor, u_pred)\n",
        "\n",
        "                    # Only normalize over the allowed domain (x >= 0)\n",
        "                    pos_mask = X_tensor.squeeze() >= 0\n",
        "                    if torch.any(pos_mask):\n",
        "                        u_pos = full_u[pos_mask]\n",
        "                        dx_pos = dx\n",
        "                        norm_loss = model.normalization_loss(u_pos, dx_pos)\n",
        "                    else:\n",
        "                        norm_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "                    # No symmetry loss for gravity well\n",
        "                    sym_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "                    # Adjusted weights for gravity well\n",
        "                    constraint_loss = 200.0 * boundary_loss + 50.0 * norm_loss\n",
        "                else:\n",
        "                    boundary_loss = model.boundary_loss(boundary_points, boundary_values)\n",
        "                    norm_loss = model.normalization_loss(model.get_complete_solution(X_tensor, u_pred), dx)\n",
        "                    sym_loss = model.symmetry_loss(X_tensor)\n",
        "                    constraint_loss = 10.0 * boundary_loss + 20.0 * norm_loss + 5.0 * sym_loss\n",
        "\n",
        "                # Decide which loss to use based on mode\n",
        "                if mode == 0:\n",
        "                    # Use Riesz energy functional for mode 0\n",
        "                    riesz_energy, lambda_value, full_u = model.riesz_loss(\n",
        "                        X_tensor, u_pred, gamma, p, potential_type, precomputed_potential\n",
        "                    )\n",
        "\n",
        "                    pde_loss, _, _, _ = model.pde_loss(\n",
        "                        X_tensor, u_pred, gamma, p, potential_type, precomputed_potential\n",
        "                    )\n",
        "\n",
        "                    # For gravity well, focus more on PDE residual\n",
        "                    if potential_type == \"gravity well\":\n",
        "                        physics_loss = pde_loss + 0.1 * riesz_energy\n",
        "                    else:\n",
        "                        physics_loss = pde_loss\n",
        "\n",
        "                    loss_type = \"Riesz energy\"\n",
        "                    monitoring_loss = constraint_loss.item()\n",
        "                else:\n",
        "                    # Use PDE residual for other modes\n",
        "                    pde_loss, _, lambda_value, full_u = model.pde_loss(\n",
        "                        X_tensor, u_pred, gamma, p, potential_type, precomputed_potential\n",
        "                    )\n",
        "                    physics_loss = pde_loss\n",
        "                    loss_type = \"PDE residual\"\n",
        "                    monitoring_loss = pde_loss.item()\n",
        "\n",
        "                # Total loss for optimization\n",
        "                total_loss = physics_loss + constraint_loss\n",
        "\n",
        "                # Backpropagate\n",
        "                total_loss.backward()\n",
        "\n",
        "                # Gradient clipping - more aggressive for gravity well\n",
        "                if potential_type == \"gravity well\":\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "                else:\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                # Record history\n",
        "                if epoch % 100 == 0:\n",
        "                    lambda_history.append(lambda_value.item())\n",
        "                    loss_history.append(total_loss.item())\n",
        "                    constraint_history.append(monitoring_loss)\n",
        "\n",
        "                    if verbose and epoch % 500 == 0:\n",
        "                        if mode == 0:\n",
        "                            print(f\"Epoch {epoch}, {loss_type}: {physics_loss.item():.6f}, \"\n",
        "                                  f\"Constraints: {monitoring_loss:.6f}, μ: {lambda_value.item():.4f}\")\n",
        "                        else:\n",
        "                            print(\n",
        "                                f\"Epoch {epoch}, {loss_type}: {physics_loss.item():.6f}, μ: {lambda_value.item():.4f}\")\n",
        "\n",
        "            # Record final chemical potential and save model\n",
        "            final_mu = lambda_history[-1] if lambda_history else 0\n",
        "            mu_logs.append((gamma, final_mu))\n",
        "            models_by_gamma[gamma] = model\n",
        "\n",
        "            # Save the training history\n",
        "            history_by_gamma[gamma] = {\n",
        "                'loss': loss_history,\n",
        "                'constraint': constraint_history,\n",
        "                'lambda': lambda_history\n",
        "            }\n",
        "\n",
        "            # Update prev_model for next gamma value (not used for gravity well)\n",
        "            if potential_type != \"gravity well\":\n",
        "                prev_model = model\n",
        "\n",
        "        # Store results for this mode\n",
        "        mu_table[mode] = mu_logs\n",
        "        models_by_mode[mode] = models_by_gamma\n",
        "        training_history[mode] = history_by_gamma\n",
        "\n",
        "    return models_by_mode, mu_table, training_history\n",
        "\n",
        "\n",
        "def gravity_well_initialization(m, mode):\n",
        "    \"\"\"Special initialization for gravity well problems\"\"\"\n",
        "    if isinstance(m, nn.Linear):\n",
        "        # Use smaller initial weights for gravity well\n",
        "        gain = 0.01 / (1.0 + 0.05 * mode)  # Much smaller initial weights\n",
        "        nn.init.xavier_normal_(m.weight, gain=gain)\n",
        "\n",
        "        # Very small bias initialization\n",
        "        m.bias.data.fill_(1e-4)\n",
        "\n",
        "\n",
        "def advanced_initialization(m, mode):\n",
        "    \"\"\"Initialize network weights with consideration of the mode number\"\"\"\n",
        "    if isinstance(m, nn.Linear):\n",
        "        # Use Xavier initialization but scale based on mode\n",
        "        gain = 1.0 / (1.0 + 0.2 * mode)  # Stronger scaling for higher modes\n",
        "        nn.init.xavier_normal_(m.weight, gain=gain)  # Normal instead of uniform\n",
        "\n",
        "        # More careful bias initialization for higher modes\n",
        "        if mode > 3:\n",
        "            m.bias.data.fill_(0.001)  # Smaller initial bias for higher modes\n",
        "        else:\n",
        "            m.bias.data.fill_(0.01)\n",
        "\n",
        "\n",
        "def plot_wavefunction(models_by_mode, X_test, gamma_values, modes, p, lb, ub, potential_type=\"box\",\n",
        "                      save_dir=\"box_plots\"):\n",
        "    \"\"\"\n",
        "    Plot wavefunctions (not densities) for different modes and gamma values.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Generate individual figures for each mode\n",
        "    for mode in modes:\n",
        "        if mode not in models_by_mode:\n",
        "            continue\n",
        "\n",
        "        # Create individual figure\n",
        "        plt.figure(figsize=(8, 6))\n",
        "\n",
        "        X_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "        dx = X_test[1, 0] - X_test[0, 0]  # Spatial step size\n",
        "\n",
        "        # Different line styles and colors\n",
        "        linestyles = ['-', '--', '-.', ':', '-', '--']\n",
        "        colors = ['k', 'b', 'r', 'g', 'm', 'c', 'slategray']\n",
        "\n",
        "        # Plot solutions for different gamma values\n",
        "        for j, gamma in enumerate(gamma_values):\n",
        "            if gamma not in models_by_mode[mode]:\n",
        "                continue\n",
        "\n",
        "            model = models_by_mode[mode][gamma]\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                u_pred = model.forward(X_tensor)\n",
        "                full_u = model.get_complete_solution(X_tensor, u_pred)\n",
        "                u_np = full_u.cpu().numpy().flatten()\n",
        "\n",
        "                # For gravity well, only normalize over x >= 0 domain\n",
        "                if potential_type == \"gravity well\":\n",
        "                    x_test_np = X_test.flatten()\n",
        "                    pos_mask = x_test_np >= 0\n",
        "                    if np.any(pos_mask):\n",
        "                        u_pos = u_np[pos_mask]\n",
        "                        dx_pos = dx\n",
        "                        norm_factor = np.sqrt(np.sum(u_pos ** 2) * dx_pos)\n",
        "                        if norm_factor > 1e-12:\n",
        "                            u_np = u_np / norm_factor\n",
        "                else:\n",
        "                    # Normal normalization for other potentials\n",
        "                    norm_factor = np.sqrt(np.sum(u_np ** 2) * dx)\n",
        "                    if norm_factor > 1e-12:\n",
        "                        u_np = u_np / norm_factor\n",
        "\n",
        "                # For mode 0 in non-gravity potentials, ensure positive values\n",
        "                if mode == 0 and potential_type != \"gravity well\":\n",
        "                    u_np = np.abs(u_np)\n",
        "\n",
        "                # Plot wavefunction (not density)\n",
        "                plt.plot(X_test.flatten(), u_np,\n",
        "                         linestyle=linestyles[j % len(linestyles)],\n",
        "                         color=colors[j % len(colors)],\n",
        "                         label=f\"γ={gamma:.1f}\")\n",
        "\n",
        "        # Configure individual figure\n",
        "        plt.title(f\"Mode {mode} Wavefunction\", fontsize=18)\n",
        "        plt.xlabel(\"x\", fontsize=18)\n",
        "        plt.ylabel(r\"$\\psi(x)$\", fontsize=18)\n",
        "        plt.grid(True)\n",
        "        plt.legend(fontsize=12)\n",
        "        plt.xlim(lb, ub)  # Set x limits to match domain\n",
        "\n",
        "        # Adjust y limits based on potential type\n",
        "        if potential_type == \"box\" and mode == 0:\n",
        "            plt.ylim(-0.2, 1.6)\n",
        "        elif potential_type == \"box\":\n",
        "            plt.ylim(-1.6, 1.6)\n",
        "        # elif potential_type == \"gravity well\":\n",
        "        #     plt.ylim(-0.8, 0.8)  # Adjust for gravity well\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_dir, f\"mode_{mode}_wavefunction_p{p}_{potential_type}.png\"), dpi=300)\n",
        "        #plt.close()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def plot_combined_grid(models_by_mode, X_test, gamma_values, modes, p, lb, ub, potential_type=\"box\",\n",
        "                       save_dir=\"box_plots\"):\n",
        "    \"\"\"\n",
        "    Create a grid of subplots showing all modes.\n",
        "    \"\"\"\n",
        "    # Determine grid dimensions\n",
        "    n_modes = len(modes)\n",
        "    n_cols = min(4, n_modes)  # Max 4 columns\n",
        "    n_rows = (n_modes + n_cols - 1) // n_cols  # Ceiling division\n",
        "\n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows))\n",
        "\n",
        "    # Flatten axes if it's a 2D array\n",
        "    if n_rows > 1 or n_cols > 1:\n",
        "        axes = axes.flatten()\n",
        "    else:\n",
        "        axes = [axes]  # Make it iterable\n",
        "\n",
        "    X_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "    dx = X_test[1, 0] - X_test[0, 0]  # Spatial step size\n",
        "\n",
        "    # Different line styles and colors\n",
        "    linestyles = ['-', '--', '-.', ':', '-', '--']\n",
        "    colors = ['k', 'b', 'r', 'g', 'm', 'c', 'slategray']\n",
        "\n",
        "    # Plot each mode in its subplot\n",
        "    for i, mode in enumerate(modes):\n",
        "        if i >= len(axes) or mode not in models_by_mode:\n",
        "            continue\n",
        "\n",
        "        ax = axes[i]\n",
        "\n",
        "        # Plot solutions for different gamma values\n",
        "        for j, gamma in enumerate(gamma_values):\n",
        "            if gamma not in models_by_mode[mode]:\n",
        "                continue\n",
        "\n",
        "            model = models_by_mode[mode][gamma]\n",
        "            model.eval()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                u_pred = model.forward(X_tensor)\n",
        "                full_u = model.get_complete_solution(X_tensor, u_pred)\n",
        "                u_np = full_u.cpu().numpy().flatten()\n",
        "\n",
        "                # Handle normalization based on potential type\n",
        "                if potential_type == \"gravity well\":\n",
        "                    x_test_np = X_test.flatten()\n",
        "                    pos_mask = x_test_np >= 0\n",
        "                    if np.any(pos_mask):\n",
        "                        u_pos = u_np[pos_mask]\n",
        "                        dx_pos = dx\n",
        "                        norm_factor = np.sqrt(np.sum(u_pos ** 2) * dx_pos)\n",
        "                        if norm_factor > 1e-12:\n",
        "                            u_np = u_np / norm_factor\n",
        "                else:\n",
        "                    # Proper normalization\n",
        "                    norm_factor = np.sqrt(np.sum(u_np ** 2) * dx)\n",
        "                    if norm_factor > 1e-12:\n",
        "                        u_np = u_np / norm_factor\n",
        "\n",
        "                # For mode 0, ensure all wavefunctions are positive (except gravity well)\n",
        "                if mode == 0 and potential_type != \"gravity well\":\n",
        "                    u_np = np.abs(u_np)\n",
        "\n",
        "                # Plot the wavefunction (not density)\n",
        "                ax.plot(X_test.flatten(), u_np,\n",
        "                        linestyle=linestyles[j % len(linestyles)],\n",
        "                        color=colors[j % len(colors)],\n",
        "                        label=f\"γ={gamma:.1f}\")\n",
        "\n",
        "        # Configure the subplot\n",
        "        ax.set_title(f\"mode {mode}\", fontsize=12)\n",
        "        ax.set_xlabel(\"x\", fontsize=12)\n",
        "        ax.set_ylabel(r\"$\\psi(x)$\", fontsize=12)\n",
        "        ax.grid(True)\n",
        "        ax.legend(fontsize=8)\n",
        "        ax.set_xlim(lb, ub)\n",
        "\n",
        "        # Set appropriate y limits\n",
        "        if potential_type == \"box\" and mode == 0:\n",
        "            ax.set_ylim(-0.2, 1.6)\n",
        "        elif potential_type == \"box\":\n",
        "            ax.set_ylim(-1.6, 1.6)\n",
        "        # elif potential_type == \"gravity well\":\n",
        "        #     ax.set_ylim(-0.8, 0.8)\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for i in range(len(modes), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    # Finalize and save combined figure\n",
        "    fig.suptitle(f\"Wavefunctions for All Modes (p={p})\", fontsize=16)\n",
        "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    fig.savefig(os.path.join(save_dir, f\"all_modes_combined_wavefunctions_p{p}_{potential_type}.png\"), dpi=300)\n",
        "    #plt.close(fig)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_mu_vs_gamma(mu_table, modes, p, potential_type=\"box\", save_dir=\"plots\"):\n",
        "    \"\"\"\n",
        "    Plot chemical potential vs. interaction strength for different modes.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    # Different markers for different modes\n",
        "    markers = ['o', 's', '^', 'v', 'D', 'x', '*', '+']\n",
        "    colors = ['k', 'b', 'r', 'g', 'm', 'c', 'orange', 'purple']\n",
        "\n",
        "    # Plot μ vs γ for each mode\n",
        "    for i, mode in enumerate(modes):\n",
        "        if mode not in mu_table:\n",
        "            continue\n",
        "\n",
        "        gamma_list, mu_list = zip(*mu_table[mode])\n",
        "        plt.plot(gamma_list, mu_list,\n",
        "                 marker=markers[i % len(markers)],\n",
        "                 color=colors[i % len(colors)],\n",
        "                 linestyle='-',\n",
        "                 label=f\"Mode {mode}\")\n",
        "\n",
        "    plt.xlabel(r\"$\\gamma$ (Interaction Strength)\", fontsize=18)\n",
        "    plt.ylabel(r\"$\\mu$ (Chemical Potential)\", fontsize=18)\n",
        "    plt.title(f\"Chemical Potential vs. Interaction Strength for All Modes (p={p})\", fontsize=18)\n",
        "    plt.grid(True)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_dir, f\"mu_vs_gamma_all_modes_p{p}_{potential_type}.png\"), dpi=300)\n",
        "    #plt.close()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def moving_average(values, window_size=10):\n",
        "    \"\"\"Apply moving average smoothing to a list of values\"\"\"\n",
        "    if len(values) < window_size:\n",
        "        return values\n",
        "    weights = np.ones(window_size) / window_size\n",
        "    return np.convolve(values, weights, mode='valid')\n",
        "\n",
        "\n",
        "def plot_improved_loss_visualization(training_history, modes, gamma_values, epochs, p, potential_type,\n",
        "                                     save_dir=\"box_plots\"):\n",
        "    \"\"\"\n",
        "    Creates informative and smoother visualizations of the training progress.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # 1. Separate plots by loss type with smoothing\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot for Mode 0 (energy minimization)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for gamma in gamma_values:\n",
        "        if 0 in training_history and gamma in training_history[0]:\n",
        "            # Get loss history for mode 0\n",
        "            loss_history = training_history[0][gamma]['loss']\n",
        "\n",
        "            # Apply smoothing to the loss data\n",
        "            window_size = min(30, len(loss_history) // 10)  # Adaptive window size\n",
        "            if window_size > 1:\n",
        "                smooth_loss = moving_average(loss_history, window_size)\n",
        "                # Adjust epoch numbers to match the smoothed array length\n",
        "                epoch_nums = np.linspace(0, epochs, len(smooth_loss))\n",
        "                plt.semilogy(epoch_nums, smooth_loss, label=f\"γ={gamma:.1f}\")\n",
        "            else:\n",
        "                epoch_nums = np.linspace(0, epochs, len(loss_history))\n",
        "                plt.semilogy(epoch_nums, loss_history, label=f\"γ={gamma:.1f}\")\n",
        "\n",
        "    plt.title(\"Mode 0: Energy Functional Minimization\", fontsize=18)\n",
        "    plt.xlabel(\"Epochs\", fontsize=18)\n",
        "    plt.ylabel(\"Energy Functional\", fontsize=18)\n",
        "    plt.grid(True)\n",
        "    plt.legend(fontsize=12)\n",
        "\n",
        "    # Plot for Modes 1+ (PDE residual minimization)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for mode in modes:\n",
        "        if mode == 0:\n",
        "            continue  # Skip mode 0 for this plot\n",
        "\n",
        "        for gamma in [0.0]:  # Focus on γ=0 for clarity\n",
        "            if mode in training_history and gamma in training_history[mode]:\n",
        "                loss_history = training_history[mode][gamma]['loss']\n",
        "\n",
        "                # Apply smoothing to the loss data\n",
        "                window_size = min(30, len(loss_history) // 10)  # Adaptive window size\n",
        "                if window_size > 1:\n",
        "                    smooth_loss = moving_average(loss_history, window_size)\n",
        "                    epoch_nums = np.linspace(0, epochs, len(smooth_loss))\n",
        "                    plt.semilogy(epoch_nums, smooth_loss, label=f\"Mode {mode}\")\n",
        "                else:\n",
        "                    epoch_nums = np.linspace(0, epochs, len(loss_history))\n",
        "                    plt.semilogy(epoch_nums, loss_history, label=f\"Mode {mode}\")\n",
        "\n",
        "    plt.title(r\"Modes 1-5: PDE Residual Minimization\", fontsize=18)\n",
        "    plt.xlabel(\"Epochs\", fontsize=18)\n",
        "    plt.ylabel(\"PDE Residual\", fontsize=18)\n",
        "    plt.grid(True)\n",
        "    plt.legend(fontsize=12)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(save_dir, f\"separated_loss_types_p{p}_{potential_type}.png\"), dpi=300)\n",
        "    #plt.close()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_all_modes_gamma_loss(training_history, modes, gamma_values, epochs, p, potential_type, save_dir=\"box_plots\"):\n",
        "    \"\"\"\n",
        "    Plot the training loss history for all modes and all gamma values.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Determine grid dimensions\n",
        "    n_modes = len(modes)\n",
        "    n_cols = min(4, n_modes)\n",
        "    n_rows = (n_modes + n_cols - 1) // n_cols\n",
        "\n",
        "    # Create figure with subplots\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows))\n",
        "\n",
        "    # Flatten axes if it's a 2D array\n",
        "    if n_rows > 1 or n_cols > 1:\n",
        "        axes = axes.flatten()\n",
        "    else:\n",
        "        axes = [axes]\n",
        "\n",
        "    # Different line styles and colors for different gamma values\n",
        "    linestyles = ['-', '--', '-.', ':', '-', '--']\n",
        "    colors = ['k', 'b', 'r', 'g', 'm', 'c', 'slategray']\n",
        "\n",
        "    # Plot each mode in its subplot\n",
        "    for i, mode in enumerate(modes):\n",
        "        if i >= len(axes) or mode not in training_history:\n",
        "            continue\n",
        "\n",
        "        ax = axes[i]\n",
        "\n",
        "        # Plot loss for each gamma value\n",
        "        for j, gamma in enumerate(gamma_values):\n",
        "            if gamma in training_history[mode]:\n",
        "                loss_history = training_history[mode][gamma]['loss']\n",
        "                epoch_nums = np.linspace(0, epochs, len(loss_history))\n",
        "\n",
        "                ax.semilogy(epoch_nums, loss_history,\n",
        "                            color=colors[j % len(colors)],\n",
        "                            linestyle=linestyles[j % len(linestyles)],\n",
        "                            label=f\"γ={gamma:.1f}\")\n",
        "\n",
        "        ax.set_title(f\"mode {mode}\", fontsize=12)\n",
        "        ax.set_xlabel(\"Epochs\", fontsize=12)\n",
        "        ax.set_ylabel(\"Loss\", fontsize=12)\n",
        "        ax.grid(True)\n",
        "        ax.legend(fontsize=6)\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for i in range(len(modes), len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    fig.suptitle(\"Training Loss for All Modes\", fontsize=16)\n",
        "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    fig.savefig(os.path.join(save_dir, f\"all_modes_gamma_loss_subplots_p{p}_{potential_type}.png\"), dpi=300)\n",
        "    #plt.close(fig)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    N_f = 8000  # Increased collocation points for gravity well\n",
        "    epochs = 3001  # More epochs for gravity well convergence\n",
        "    layers = [1, 64, 64, 64, 1]  # Optimized network architecture\n",
        "\n",
        "    # Gamma values from the paper\n",
        "    gamma_values = [0.0, 10.0, 20.0, 40.0, 60.0, 80.0, 100.0]\n",
        "\n",
        "    # Include modes 0 through 2 (can extend to more once working)\n",
        "    modes = [0, 1, 2]\n",
        "\n",
        "    # Nonlinearity powers\n",
        "    nonlinearity_powers = [3]\n",
        "\n",
        "    for p in nonlinearity_powers:\n",
        "        # Focus on gravity well first\n",
        "        all_potentials = ['gravity well']\n",
        "\n",
        "        for potential_type in all_potentials:\n",
        "            if potential_type == 'box':\n",
        "                lb, ub = 0, 1\n",
        "            elif potential_type == 'gravity well':\n",
        "                lb, ub = -1, 20  # Optimized domain\n",
        "            else:\n",
        "                lb, ub = -10, 10\n",
        "\n",
        "            # Create uniform grid with better resolution for gravity well\n",
        "            if potential_type == 'gravity well':\n",
        "                # Use non-uniform grid with higher density near x=0\n",
        "                x_neg = np.linspace(lb, 0, N_f // 8)  # Negative domain\n",
        "                x_pos = np.linspace(0, ub, 7 * N_f // 8)  # Positive domain (higher density)\n",
        "                X = np.concatenate([x_neg[:-1], x_pos]).reshape(-1, 1)  # Remove duplicate at x=0\n",
        "\n",
        "                # Test grid\n",
        "                x_test_neg = np.linspace(lb, 0, 100)\n",
        "                x_test_pos = np.linspace(0, ub, 900)\n",
        "                X_test = np.concatenate([x_test_neg[:-1], x_test_pos]).reshape(-1, 1)\n",
        "            else:\n",
        "                X = np.linspace(lb, ub, N_f).reshape(-1, 1)\n",
        "                X_test = np.linspace(lb, ub, 1000).reshape(-1, 1)\n",
        "\n",
        "            # Create specific directory\n",
        "            p_save_dir = f\"plots_p{p}_{potential_type}_fixed\"\n",
        "            os.makedirs(p_save_dir, exist_ok=True)\n",
        "\n",
        "            # Train models with improved implementation\n",
        "            print(f\"\\nStarting training for {potential_type} potential...\")\n",
        "            models_by_mode, mu_table, training_history = train_gpe_model(\n",
        "                gamma_values, modes, p, X, lb, ub, layers, epochs,\n",
        "                potential_type, lr=5e-4, verbose=True  # Lower learning rate for stability\n",
        "            )\n",
        "            print(\"Training completed!\")\n",
        "\n",
        "            # Plot wavefunctions for individual modes\n",
        "            print(\"Generating individual mode plots...\")\n",
        "            plot_wavefunction(models_by_mode, X_test, gamma_values, modes, p, lb, ub, potential_type, p_save_dir)\n",
        "\n",
        "            # Plot μ vs γ for all modes\n",
        "            print(\"Generating chemical potential vs. gamma plot...\")\n",
        "            plot_mu_vs_gamma(mu_table, modes, p, potential_type, p_save_dir)\n",
        "\n",
        "            # Plot loss history\n",
        "            print(\"Generating loss plots...\")\n",
        "            plot_improved_loss_visualization(training_history, modes, gamma_values, epochs, p, potential_type,\n",
        "                                             p_save_dir)\n",
        "            plot_all_modes_gamma_loss(training_history, modes, gamma_values, epochs, p, potential_type, p_save_dir)\n",
        "\n",
        "            print(f\"Completed all calculations for {potential_type} potential\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqOZ-EU_R4dO",
        "outputId": "339bda2c-e58c-48a2-c522-b3818b76e80c"
      },
      "id": "uqOZ-EU_R4dO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training for gravity well potential...\n",
            "\n",
            "===== Training for mode 0 =====\n",
            "\n",
            "Training for γ = 0.00, mode = 0, nonlinearity p = 3, potential = gravity well\n",
            "Epoch 0, Riesz energy: 0.513624, Constraints: 50.000000, μ: 5.1362\n",
            "Epoch 500, Riesz energy: 1.800436, Constraints: 4.090973, μ: 4.3043\n",
            "Epoch 1000, Riesz energy: 1.357813, Constraints: 1.418929, μ: 4.5329\n",
            "Epoch 1500, Riesz energy: 0.262508, Constraints: 0.001656, μ: 2.0755\n",
            "Epoch 2000, Riesz energy: 0.196963, Constraints: 0.005250, μ: 1.8983\n",
            "Epoch 2500, Riesz energy: 0.193113, Constraints: 0.005914, μ: 1.8984\n",
            "Epoch 3000, Riesz energy: 0.191661, Constraints: 0.006130, μ: 1.8983\n",
            "\n",
            "Training for γ = 10.00, mode = 0, nonlinearity p = 3, potential = gravity well\n",
            "Epoch 0, Riesz energy: 1.120863, Constraints: 50.000011, μ: 11.2086\n",
            "Epoch 500, Riesz energy: 0.948682, Constraints: 3.785264, μ: 4.8236\n",
            "Epoch 1000, Riesz energy: 0.707542, Constraints: 2.905851, μ: 4.4889\n",
            "Epoch 1500, Riesz energy: 1.162154, Constraints: 1.865136, μ: 5.1268\n",
            "Epoch 2000, Riesz energy: 1.373245, Constraints: 0.032299, μ: 6.3436\n",
            "Epoch 2500, Riesz energy: 0.687043, Constraints: 0.006215, μ: 4.7208\n",
            "Epoch 3000, Riesz energy: 0.454092, Constraints: 0.006112, μ: 4.3563\n",
            "\n",
            "Training for γ = 20.00, mode = 0, nonlinearity p = 3, potential = gravity well\n",
            "Epoch 0, Riesz energy: 1.323254, Constraints: 50.000027, μ: 13.2325\n",
            "Epoch 500, Riesz energy: 0.667488, Constraints: 3.921050, μ: 5.6703\n",
            "Epoch 1000, Riesz energy: 0.698817, Constraints: 2.317369, μ: 5.6280\n",
            "Epoch 1500, Riesz energy: 1.097784, Constraints: 1.588632, μ: 5.8237\n",
            "Epoch 2000, Riesz energy: 1.308442, Constraints: 1.190187, μ: 5.9302\n",
            "Epoch 2500, Riesz energy: 1.689374, Constraints: 0.602189, μ: 6.3177\n",
            "Epoch 3000, Riesz energy: 1.139307, Constraints: 0.029595, μ: 6.3522\n",
            "\n",
            "Training for γ = 40.00, mode = 0, nonlinearity p = 3, potential = gravity well\n",
            "Epoch 0, Riesz energy: 1.166524, Constraints: 50.000229, μ: 11.6652\n",
            "Epoch 500, Riesz energy: 0.870256, Constraints: 4.154333, μ: 7.1183\n",
            "Epoch 1000, Riesz energy: 0.821120, Constraints: 2.220635, μ: 7.2732\n",
            "Epoch 1500, Riesz energy: 0.928573, Constraints: 1.821960, μ: 7.4195\n",
            "Epoch 2000, Riesz energy: 0.883159, Constraints: 1.763498, μ: 7.5069\n",
            "Epoch 2500, Riesz energy: 0.915151, Constraints: 1.690079, μ: 7.6440\n",
            "Epoch 3000, Riesz energy: 0.834938, Constraints: 1.800040, μ: 7.5734\n",
            "\n",
            "Training for γ = 60.00, mode = 0, nonlinearity p = 3, potential = gravity well\n",
            "Epoch 0, Riesz energy: 0.907929, Constraints: 50.000004, μ: 9.0793\n",
            "Epoch 500, Riesz energy: 1.201945, Constraints: 4.457424, μ: 8.4784\n",
            "Epoch 1000, Riesz energy: 1.118176, Constraints: 1.697511, μ: 8.8680\n",
            "Epoch 1500, Riesz energy: 0.996143, Constraints: 1.587507, μ: 9.0173\n",
            "Epoch 2000, Riesz energy: 0.997044, Constraints: 1.535377, μ: 9.0653\n",
            "Epoch 2500, Riesz energy: 1.014354, Constraints: 1.497758, μ: 9.0656\n",
            "Epoch 3000, Riesz energy: 1.027868, Constraints: 1.455921, μ: 9.0895\n",
            "\n",
            "Training for γ = 80.00, mode = 0, nonlinearity p = 3, potential = gravity well\n",
            "Epoch 0, Riesz energy: 0.749978, Constraints: 49.999996, μ: 7.4998\n",
            "Epoch 500, Riesz energy: 1.676059, Constraints: 4.723894, μ: 9.6193\n",
            "Epoch 1000, Riesz energy: 1.170130, Constraints: 1.498219, μ: 10.2213\n",
            "Epoch 1500, Riesz energy: 1.107840, Constraints: 1.491145, μ: 10.2933\n",
            "Epoch 2000, Riesz energy: 1.119056, Constraints: 1.439039, μ: 10.2929\n",
            "Epoch 2500, Riesz energy: 1.126590, Constraints: 1.400057, μ: 10.3139\n",
            "Epoch 3000, Riesz energy: 1.140057, Constraints: 1.366842, μ: 10.3272\n",
            "\n",
            "Training for γ = 100.00, mode = 0, nonlinearity p = 3, potential = gravity well\n",
            "Epoch 0, Riesz energy: 1.025549, Constraints: 50.000023, μ: 10.2555\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}