{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efbqfOtOZasn",
      "metadata": {
        "id": "efbqfOtOZasn"
      },
      "source": [
        "This notebook implements concepts from the [Multi-Objective Loss Balancing for Physics-Informed Deep Learning paper](https://arxiv.org/abs/2110.09813). It highlights the gains in performance when applying Loss Balancing Schemes to PINN training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3nYdXyrr-Z7h",
      "metadata": {
        "id": "3nYdXyrr-Z7h"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "BMnx60Sj-Z7j",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMnx60Sj-Z7j",
        "outputId": "edbfb7df-a3fd-4e8d-8360-8fc4d3c29fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.autograd import grad\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hglIb1ul-Z7n",
      "metadata": {
        "id": "hglIb1ul-Z7n"
      },
      "source": [
        "# Physics Informed Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "NFVJh4jB-Z7o",
      "metadata": {
        "id": "NFVJh4jB-Z7o"
      },
      "outputs": [],
      "source": [
        "class GrossPitaevskiiPINN(nn.Module):\n",
        "    \"\"\"\n",
        "    Physics-Informed Neural Network (PINN) for solving the 1D Gross-Pitaevskii Equation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, layers, hbar=1.0, m=1.0, g=100.0):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        layers : list of int\n",
        "            Neural network architecture, each entry defines the number of neurons in that layer.\n",
        "        hbar : float, optional\n",
        "            Reduced Planck's constant (default is 1.0).\n",
        "        m : float, optional\n",
        "            Mass of the particle (default is 1.0).\n",
        "        g : float, optional\n",
        "            Interaction strength (default is 100.0).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.layers = layers\n",
        "        self.network = self.build_network()\n",
        "        self.g = g  # Interaction strength\n",
        "        self.hbar = hbar  # Planck's constant, fixed\n",
        "        self.m = m  # Particle mass, fixed\n",
        "\n",
        "    def build_network(self):\n",
        "        \"\"\"\n",
        "        Build the neural network with sine activation functions between layers.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        nn.Sequential\n",
        "            A PyTorch sequential model representing the neural network architecture.\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            layers.append(nn.Linear(self.layers[i], self.layers[i + 1]))\n",
        "            if i < len(self.layers) - 2:\n",
        "                layers.append(nn.Tanh())\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        Forward pass through the neural network.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : torch.Tensor\n",
        "            Input tensor containing spatial points (collocation points).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Output tensor representing the predicted solution.\n",
        "        \"\"\"\n",
        "        return self.network(inputs)\n",
        "\n",
        "    def compute_potential(self, x, potential_type=\"gaussian\", **kwargs):\n",
        "        \"\"\"\n",
        "        Compute a symmetric or asymmetric potential function for the 1D domain.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Input tensor of spatial coordinates.\n",
        "        potential_type : str, optional\n",
        "            Type of potential. Options are:\n",
        "            \"gaussian\", \"harmonic\", \"double_well\", \"box\", \"periodic\", \"linear\", \"step\", \"sine\".\n",
        "            By default \"gaussian\".\n",
        "        kwargs : dict\n",
        "            Additional parameters specific to each potential type.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        V : torch.Tensor\n",
        "            Tensor of potential values at the input points.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        ValueError\n",
        "            If the potential type is not recognized.\n",
        "        \"\"\"\n",
        "        if potential_type == \"gaussian\":\n",
        "            a = kwargs.get('a', 0.0)  # Center of the Gaussian\n",
        "            V = torch.exp(-(x - a) ** 2)\n",
        "\n",
        "        elif potential_type == \"harmonic\":\n",
        "            omega = kwargs.get('omega', 1.0)  # Frequency for harmonic potential\n",
        "            V = 0.5 * omega ** 2 * x ** 2\n",
        "\n",
        "        elif potential_type == \"double_well\":\n",
        "            a = kwargs.get('a', 1.0)  # Quartic coefficient\n",
        "            b = kwargs.get('b', 1.0)  # Quadratic coefficient\n",
        "            V = a * x ** 4 - b * x ** 2\n",
        "\n",
        "        elif potential_type == \"box\":\n",
        "            L = kwargs.get('L', 10.0)  # Length of the box\n",
        "            V = torch.where(torch.abs(x) <= L / 2, torch.tensor(0.0), torch.tensor(float('inf')))\n",
        "\n",
        "        elif potential_type == \"periodic\":\n",
        "            V0 = kwargs.get('V0', 1.0)  # Depth of the potential\n",
        "            k = kwargs.get('k', 2 * np.pi / 5.0)  # Wave number for periodic potential\n",
        "            V = V0 * torch.cos(k * x) ** 2\n",
        "\n",
        "        elif potential_type == \"linear\":\n",
        "            F = kwargs.get('F', 1.0)  # Force constant for linear potential\n",
        "            V = F * x\n",
        "\n",
        "        elif potential_type == \"step\":\n",
        "            V0 = kwargs.get('V0', 1.0)  # Step height\n",
        "            x0 = kwargs.get('x0', 0.0)  # Position of the step\n",
        "            V = torch.where(x > x0, torch.tensor(V0), torch.tensor(0.0))\n",
        "\n",
        "        elif potential_type == \"sine\":\n",
        "            a = kwargs.get('a', 0.5)  # Center of the sine potential\n",
        "            l = kwargs.get('l', 1.0)  # Length scale for sine potential\n",
        "            V = torch.sin(torch.pi * (x - (a - l / 2)) / l)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown potential type: {potential_type}\")\n",
        "\n",
        "        return V\n",
        "\n",
        "    def boundary_loss(self, boundary_points, boundary_values):\n",
        "        \"\"\"\n",
        "        Compute the boundary loss (MSE) for the boundary conditions.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        boundary_points : torch.Tensor\n",
        "            Input tensor of boundary spatial points.\n",
        "        boundary_values : torch.Tensor\n",
        "            Tensor of boundary values (for Dirichlet conditions).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Mean squared error (MSE) at the boundary points.\n",
        "        \"\"\"\n",
        "        u_pred = self.forward(boundary_points)\n",
        "        return torch.mean((u_pred - boundary_values) ** 2)\n",
        "\n",
        "    def riesz_loss(self, predictions, inputs, eta, potential_type):\n",
        "        \"\"\"\n",
        "        Compute the Riesz energy loss for the Gross-Pitaevskii equation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        predictions : torch.Tensor\n",
        "            Predicted solution from the network.\n",
        "        inputs : torch.Tensor\n",
        "            Input tensor of spatial coordinates (collocation points).\n",
        "        eta : float\n",
        "            Interaction strength.\n",
        "        potential_type : str\n",
        "            Type of potential function to use.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Riesz energy loss value.\n",
        "        \"\"\"\n",
        "        u = predictions\n",
        "\n",
        "        if not inputs.requires_grad:\n",
        "            inputs = inputs.clone().detach().requires_grad_(True)\n",
        "        u_x = torch.autograd.grad(outputs=predictions, inputs=inputs,\n",
        "                                  grad_outputs=torch.ones_like(predictions),\n",
        "                                  create_graph=True, retain_graph=True)[0]\n",
        "\n",
        "        laplacian_term = torch.mean(u_x ** 2)  # Kinetic term\n",
        "        V = self.compute_potential(inputs, potential_type)\n",
        "        potential_term = torch.mean(V * u ** 2)  # Potential term\n",
        "        interaction_term = 0.5 * eta * torch.mean(u ** 4)  # Interaction term\n",
        "\n",
        "        riesz_energy = 0.5 * (laplacian_term + potential_term + interaction_term)\n",
        "\n",
        "        return riesz_energy\n",
        "\n",
        "    def pde_loss(self, inputs, predictions, eta, potential_type):\n",
        "        \"\"\"\n",
        "        Compute the PDE loss for the Gross-Pitaevskii equation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : torch.Tensor\n",
        "            Input tensor of spatial coordinates (collocation points).\n",
        "        predictions : torch.Tensor\n",
        "            Predicted solution from the network.\n",
        "        eta : float\n",
        "            Interaction strength.\n",
        "        potential_type : str\n",
        "            Type of potential function to use.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple\n",
        "            Tuple containing:\n",
        "                - torch.Tensor: PDE loss value.\n",
        "                - torch.Tensor: PDE residual.\n",
        "                - torch.Tensor: Smallest eigenvalue (lambda).\n",
        "        \"\"\"\n",
        "        u = predictions\n",
        "\n",
        "        # Compute first and second derivatives with respect to x\n",
        "        u_x = grad(u, inputs, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
        "        u_xx = grad(u_x, inputs, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
        "\n",
        "        # Compute λ from the energy functional\n",
        "        V = self.compute_potential(inputs, potential_type)\n",
        "        lambda_pde = torch.mean(u_x ** 2 + V * u ** 2 + eta * u ** 4) / torch.mean(u ** 2)\n",
        "\n",
        "        # Residual of the 1D Gross-Pitaevskii equation\n",
        "        pde_residual = -u_xx + V * u + eta * torch.abs(u ** 2) * u - lambda_pde * u\n",
        "\n",
        "        # Regularization: See https://arxiv.org/abs/2010.05075\n",
        "\n",
        "        # Term 1: L_f = 1 / (f(x, λ))^2, penalizes the network if the PDE residual is close to zero to avoid trivial eigenfunctions\n",
        "        L_f = 1 / (torch.mean(u ** 2) + 1e-2)\n",
        "\n",
        "        # Term 2: L_λ = 1 / λ^2, penalizes small eigenvalues λ, ensuring non-trivial eigenvalues\n",
        "        L_lambda = 1 / (lambda_pde ** 2 + 1e-6)\n",
        "\n",
        "        # Term 3: L_drive = e^(-λ + c), encourages λ to grow, preventing collapse to small values\n",
        "        L_drive = torch.exp(-lambda_pde + 1.0)\n",
        "\n",
        "        # PDE loss (residual plus regularization terms)\n",
        "        pde_loss = torch.mean(pde_residual ** 2)  # + L_lambda + L_f\n",
        "\n",
        "        return pde_loss, pde_residual, lambda_pde\n",
        "\n",
        "    def symmetry_loss(self, collocation_points, lb, ub):\n",
        "        \"\"\"\n",
        "        Compute the symmetry loss to enforce u(x) = u((a+b)-x).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        collocation_points : torch.Tensor\n",
        "            Tensor of interior spatial points.\n",
        "        lb : torch.Tensor\n",
        "            Lower bound of interval.\n",
        "        ub: torch.Tensor\n",
        "            Upper bound of interval.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        sym_loss : torch.Tensor\n",
        "            The mean squared error enforcing symmetry u(x) = u((a+b)-x).\n",
        "        \"\"\"\n",
        "        # Reflect points across the center of the domain\n",
        "        x_reflected = (lb + ub) - collocation_points\n",
        "\n",
        "        # Evaluate u(x) and u((a+b)-x)\n",
        "        u_original = self.forward(collocation_points)\n",
        "        u_reflected = self.forward(x_reflected)\n",
        "\n",
        "        # Compute MSE to enforce symmetry\n",
        "        sym_loss = torch.mean((u_original - u_reflected) ** 2)\n",
        "        return sym_loss\n",
        "\n",
        "    def total_loss(self, collocation_points, boundary_points, boundary_values, eta, lb, ub, weights, potential_type):\n",
        "        \"\"\"\n",
        "        Compute the total loss combining boundary loss, Riesz energy loss,\n",
        "        PDE loss, L^2 norm regularization loss, and symmetry loss.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        collocation_points : torch.Tensor\n",
        "            Input tensor of spatial coordinates for the interior points.\n",
        "        boundary_points : torch.Tensor\n",
        "            Input tensor of boundary spatial points.\n",
        "        boundary_values : torch.Tensor\n",
        "            Tensor of boundary values (for Dirichlet conditions).\n",
        "        eta : float\n",
        "            Interaction strength.\n",
        "        lb : torch.Tensor\n",
        "            Lower bound of interval.\n",
        "        ub : torch.Tensor\n",
        "            Upper bound of interval.\n",
        "        weights : list\n",
        "            Weights for different loss terms.\n",
        "        potential_type : str\n",
        "            Type of potential function to use\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        total_loss : torch.Tensor\n",
        "            Total loss value.\n",
        "        \"\"\"\n",
        "\n",
        "        # Compute individual loss components\n",
        "        data_loss = self.boundary_loss(boundary_points, boundary_values)\n",
        "        riesz_energy_loss = self.riesz_loss(self.forward(collocation_points), collocation_points, eta, potential_type)\n",
        "        pde_loss, _, _ = self.pde_loss(collocation_points, self.forward(collocation_points), eta, potential_type)\n",
        "        norm_loss = (torch.norm(self.forward(collocation_points), p=2) - 1) ** 2\n",
        "        sym_loss = self.symmetry_loss(collocation_points, lb, ub)\n",
        "\n",
        "        # Scaling factor for pde loss and riesz energy loss\n",
        "        domain_length = ub - lb\n",
        "\n",
        "        # Compute weighted losses and total loss\n",
        "        losses = [data_loss, riesz_energy_loss  / domain_length, pde_loss / domain_length, norm_loss, sym_loss]\n",
        "        weighted_losses = [weights[i] * loss for i, loss in enumerate(losses)]\n",
        "        total_loss = sum(weighted_losses)\n",
        "\n",
        "        return total_loss, data_loss, riesz_energy_loss, pde_loss, norm_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FzMOyXAj7jey",
      "metadata": {
        "id": "FzMOyXAj7jey"
      },
      "source": [
        "# Initialize Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "GyMrRGdE7lB2",
      "metadata": {
        "id": "GyMrRGdE7lB2"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    \"\"\"\n",
        "    Initialize the weights of the neural network layers using Xavier uniform initialization.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    m : torch.nn.Module\n",
        "        A layer of the neural network. If it is a linear layer, its weights and biases are initialized.\n",
        "    \"\"\"\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AKKgTNHo24k4",
      "metadata": {
        "id": "AKKgTNHo24k4"
      },
      "source": [
        "# Prepare Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1kAWdOgL26tv",
      "metadata": {
        "id": "1kAWdOgL26tv"
      },
      "outputs": [],
      "source": [
        "def prepare_training_data(N_u, N_f, lb, ub):\n",
        "    \"\"\"\n",
        "    Prepare boundary and collocation points for training.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    N_u : int\n",
        "        Number of boundary points.\n",
        "    N_f : int\n",
        "        Number of collocation points.\n",
        "    lb : np.ndarray\n",
        "        Lower bounds of the domain.\n",
        "    ub : np.ndarray\n",
        "        Upper bounds of the domain.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    collocation_points : np.ndarray\n",
        "        Collocation points.\n",
        "    boundary_points : np.ndarray\n",
        "        Boundary points.\n",
        "    boundary_values : np.ndarray\n",
        "        Boundary values.\n",
        "    \"\"\"\n",
        "\n",
        "    # Boundary of interval\n",
        "    boundary_points = np.array([[lb], [ub]])\n",
        "    boundary_values = np.zeros((2, 1))\n",
        "\n",
        "    # Dynamically sample points inside the interval\n",
        "    collocation_points = np.random.rand(N_f, 1) * (ub - lb) + lb\n",
        "\n",
        "    return collocation_points, boundary_points, boundary_values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B0dvfxBOmPlR",
      "metadata": {
        "id": "B0dvfxBOmPlR"
      },
      "source": [
        "# Train PINN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "FXsGZVhYmS1t",
      "metadata": {
        "id": "FXsGZVhYmS1t"
      },
      "outputs": [],
      "source": [
        "def train_pinn(X, N_u, N_f, layers, eta, epochs, lb, ub, weights, model_save_path, potential_type):\n",
        "    \"\"\"\n",
        "    Train the Physics-Informed Neural Network (PINN) for the 1D Gross-Pitaevskii equation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : np.ndarray\n",
        "        Input data for the neural network\n",
        "    N_u : int\n",
        "        Number of boundary points\n",
        "    N_f : int\n",
        "        Number of collocation points (interior points) for the physics-based loss\n",
        "    layers : list of int\n",
        "        Architecture of the neural network\n",
        "    eta : float\n",
        "        Interaction strength\n",
        "    epochs: int\n",
        "        Number of epochs\n",
        "    lb : int\n",
        "        Lower bound of interval.\n",
        "    ub : int\n",
        "        Upper bound of interval.\n",
        "    weights : list\n",
        "        Weights for different loss terms.\n",
        "    model_save_path : str\n",
        "        Save path for trained model\n",
        "    potential_type: str\n",
        "        Type of potential function to use\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : GrossPitaevskiiPINN\n",
        "        The trained model\n",
        "    loss_history : list\n",
        "        List of loss values recorded during training\n",
        "    \"\"\"\n",
        "    # Instantiate the PINN model and initialize its weights\n",
        "    model = GrossPitaevskiiPINN(layers).to(device)\n",
        "    model.apply(initialize_weights)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=25, factor=0.5, verbose=True)\n",
        "\n",
        "    # Prepare training data (collocation and boundary points)\n",
        "    collocation_points, boundary_points, boundary_values = prepare_training_data(N_u, N_f, lb, ub)\n",
        "\n",
        "    # Convert data to PyTorch tensors and move to device\n",
        "    collocation_points_tensor = torch.tensor(collocation_points, dtype=torch.float32, requires_grad=True).to(device)\n",
        "    boundary_points_tensor = torch.tensor(boundary_points, dtype=torch.float32).to(device)\n",
        "    boundary_values_tensor = torch.tensor(boundary_values, dtype=torch.float32).to(device)\n",
        "    lb_tensor = torch.tensor(lb, dtype=torch.float32).to(device)\n",
        "    ub_tensor = torch.tensor(ub, dtype=torch.float32).to(device)\n",
        "\n",
        "    loss_history = []\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate the total loss (boundary, Riesz energy, PDE, normalization, and symmetry losses)\n",
        "        loss, data_loss, riesz_energy, pde_loss, norm_loss = model.total_loss(collocation_points_tensor,\n",
        "                                                                              boundary_points_tensor,\n",
        "                                                                              boundary_values_tensor,\n",
        "                                                                              eta,\n",
        "                                                                              lb_tensor, ub_tensor,\n",
        "                                                                              weights, potential_type)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Clip gradients\n",
        "        optimizer.step()\n",
        "\n",
        "        # Scheduler step (for ReduceLROnPlateau)\n",
        "        scheduler.step(loss)\n",
        "\n",
        "        # Record the total loss every 100 epochs\n",
        "        if epoch % 100 == 0:\n",
        "            loss_history.append(loss.item())\n",
        "\n",
        "        # Record the pde loss and lambda every 10000 epochs\n",
        "        if epoch % 10000 == 0:\n",
        "            print(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.6f}')\n",
        "            pde_loss, _, lambda_pde = model.pde_loss(collocation_points_tensor, model.forward(collocation_points_tensor), eta, potential_type)\n",
        "\n",
        "    return model, loss_history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8P5eHv-QCQiE",
      "metadata": {
        "id": "8P5eHv-QCQiE"
      },
      "source": [
        "# Normalize Wave Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "wUq16rY6CUd9",
      "metadata": {
        "id": "wUq16rY6CUd9"
      },
      "outputs": [],
      "source": [
        "def normalize_wave_function(u):\n",
        "    \"\"\"\n",
        "    Normalize the wave function with respect to its maximum value.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    u : torch.Tensor\n",
        "        The predicted wave function.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The normalized wave function.\n",
        "    \"\"\"\n",
        "    return np.abs(u) / np.max(np.abs(u))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "t7r4H0TVkyZb",
      "metadata": {
        "id": "t7r4H0TVkyZb"
      },
      "source": [
        "# Plot Potential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "__9usRWzk15-",
      "metadata": {
        "id": "__9usRWzk15-"
      },
      "outputs": [],
      "source": [
        "def plot_potential_1D(X_test, potential):\n",
        "    \"\"\"\n",
        "    Plot the 1D potential function.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X_test : np.ndarray\n",
        "        The test points where the potential is computed.\n",
        "    potential : np.ndarray\n",
        "        The computed potential values at the test points.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(6, 5))\n",
        "\n",
        "    # X_test is the x-values (positions) of the 1D potential\n",
        "    plt.plot(X_test, potential, label='Potential $V(x)$', color='green')\n",
        "\n",
        "    plt.title('Potential $V(x)$ in 1D')\n",
        "    plt.xlabel('$x$')\n",
        "    plt.ylabel('$V(x)$')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mS-f4Mkzk4KD",
      "metadata": {
        "id": "mS-f4Mkzk4KD"
      },
      "source": [
        "# Train and Save PINN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7XcQoQhFk78S",
      "metadata": {
        "id": "7XcQoQhFk78S"
      },
      "outputs": [],
      "source": [
        "def train_and_save_pinn(X, N_u, N_f, layers, eta, epochs, lb, ub, weights, model_save_path, potential_type):\n",
        "    \"\"\"\n",
        "    Train the Physics-Informed Neural Network (PINN) model and save it.\n",
        "\n",
        "    This function trains a PINN model for the 1D Gross-Pitaevskii equation with a specific interaction\n",
        "    strength (eta) and saves the trained model to a specified path. It also returns the trained model\n",
        "    and the loss history recorded during training.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : np.ndarray\n",
        "        Input data for the training (e.g., spatial domain points).\n",
        "    N_u : int\n",
        "        Number of boundary points.\n",
        "    N_f : int\n",
        "        Number of collocation points (interior points) for physics-based loss.\n",
        "    layers : list of int\n",
        "        Architecture of the neural network, defined as a list of layer sizes.\n",
        "        For example, [1, 100, 100, 100, 1] represents an input layer with 1 neuron,\n",
        "        three hidden layers with 100 neurons each, and an output layer with 1 neuron.\n",
        "    eta : float\n",
        "        Interaction strength parameter for the Gross-Pitaevskii equation.\n",
        "    epochs : int\n",
        "        Number of training epochs.\n",
        "    lb : int\n",
        "        Lower bound of interval.\n",
        "    ub : int\n",
        "        Upper bound of interval.\n",
        "    weights : list\n",
        "        Weights for different loss terms.\n",
        "    model_save_path : str\n",
        "        File name to save the trained model weights (e.g., 'model_eta_1.pth').\n",
        "    potential_type: str\n",
        "        Type of potential function to use\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : GrossPitaevskiiPINN\n",
        "        The trained PINN model.\n",
        "    loss_history : list of float\n",
        "        A list of loss values recorded during training for each epoch\n",
        "    \"\"\"\n",
        "    model = GrossPitaevskiiPINN(layers).to(device)\n",
        "    model.apply(initialize_weights)\n",
        "\n",
        "    # Train the model\n",
        "    model, loss_history = train_pinn(X, N_u=N_u, N_f=N_f, layers=layers, eta=eta, epochs=epochs, lb=lb, ub=ub,\n",
        "                                     weights=weights, model_save_path=model_save_path, potential_type=potential_type)\n",
        "\n",
        "    # Directory to save the models\n",
        "    model_save_dir = 'models'\n",
        "    os.makedirs(model_save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "    # Save model after training\n",
        "    save_model_path = os.path.join(model_save_dir, model_save_path)\n",
        "    torch.save(model.state_dict(), save_model_path)  # Save model weights\n",
        "\n",
        "    return model, loss_history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vjY89lOvYF0h",
      "metadata": {
        "id": "vjY89lOvYF0h"
      },
      "source": [
        "# Predict and Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "YZ-IcULzYIDu",
      "metadata": {
        "id": "YZ-IcULzYIDu"
      },
      "outputs": [],
      "source": [
        "def predict_and_plot(models, etas, X_test, save_path='plots/predicted_solutions.png', potential_type='gaussian'):\n",
        "    \"\"\"\n",
        "    Predict and plot the solutions for all models and save the plot.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    models : list of models\n",
        "        A list of trained models.\n",
        "    etas : list of float\n",
        "        A list of eta values corresponding to each model.\n",
        "    X_test : np.ndarray\n",
        "        Test points along the 1D interval.\n",
        "    save_path : str, optional\n",
        "        The path to save the plot image (default is 'plots/predicted_solutions.png').\n",
        "    potential_type  : str, optional\n",
        "        Type of potential function to use. Default is 'gaussian'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Ensure the plots directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for model, eta in zip(models, etas):\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "        u_pred = model(X_test_tensor).detach().cpu().numpy()\n",
        "        u_pred_normalized = normalize_wave_function(u_pred)\n",
        "        plt.plot(X_test, u_pred_normalized, label=f'Predicted Solution ($\\\\eta$ ≈ {eta})')\n",
        "\n",
        "    plt.title(f'Ground State Solution by PINN {potential_type.capitalize()} Potential', fontsize=\"xx-large\")\n",
        "    plt.xlabel('x', fontsize=\"xx-large\")\n",
        "    plt.ylabel('u(x)', fontsize=\"xx-large\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(fontsize=\"large\")\n",
        "\n",
        "    # Set larger tick sizes\n",
        "    plt.xticks(fontsize=\"x-large\")\n",
        "    plt.yticks(fontsize=\"x-large\")\n",
        "\n",
        "    # Save the plot\n",
        "    save_path = save_path.format(potential_type=potential_type)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kE42RFBuYLPG",
      "metadata": {
        "id": "kE42RFBuYLPG"
      },
      "source": [
        "# Plot Loss History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "WnUKr0ukYOex",
      "metadata": {
        "id": "WnUKr0ukYOex"
      },
      "outputs": [],
      "source": [
        "def plot_loss_history(loss_histories, etas, save_path='plots/loss_history.png', potential_type='gaussian'):\n",
        "    \"\"\"\n",
        "    Plot the training loss history for different values of eta and save the plot.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    loss_histories : list of lists\n",
        "        A list where each element is a list of loss values recorded during training\n",
        "        for a specific eta.\n",
        "    etas : list of float\n",
        "        A list of eta values corresponding to each loss history.\n",
        "    save_path : str, optional\n",
        "        The path to save the plot image (default is 'plots/loss_history.png').\n",
        "    potential_type  : str, optional\n",
        "        Type of potential function to use. Default is 'gaussian'.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Ensure the plots directory exists\n",
        "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for loss_history, eta in zip(loss_histories, etas):\n",
        "        plt.plot(loss_history, label=f'Loss ($\\\\eta$ ≈ {eta})')\n",
        "\n",
        "    plt.xlabel('Training step (x 100)', fontsize=\"xx-large\")\n",
        "    plt.ylabel('Total Loss', fontsize=\"xx-large\")\n",
        "    plt.yscale('log')\n",
        "    plt.title(f'Loss History for Different Interaction Strengths ($\\\\eta$) for {potential_type.capitalize()} Potential', fontsize=\"xx-large\")\n",
        "    plt.legend(fontsize=\"large\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Set larger tick sizes\n",
        "    plt.xticks(fontsize=\"x-large\")\n",
        "    plt.yticks(fontsize=\"x-large\")\n",
        "\n",
        "    # Save the plot\n",
        "    save_path = save_path.format(potential_type=potential_type)\n",
        "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7RmggB2e-Z7r",
      "metadata": {
        "id": "7RmggB2e-Z7r"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "js3eLQbPlIgm",
      "metadata": {
        "id": "js3eLQbPlIgm"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "N_u = 200  # Number of boundary points\n",
        "N_f = 4000  # Number of collocation points\n",
        "epochs = 20001 # Number of iterations of training\n",
        "layers = [1, 100, 100, 100, 1]  # Neural network architecture\n",
        "lb, ub = -10, 10  # Boundary limits\n",
        "X = np.linspace(lb, ub, N_f).reshape(-1, 1)  # Input grid for training\n",
        "\n",
        "# Test points\n",
        "X_test = np.linspace(lb, ub, N_f).reshape(-1, 1)  # Test points for prediction\n",
        "etas = [1, 10, 100, 500, 1000]  # Interaction strengths\n",
        "\n",
        "# Weights for loss terms\n",
        "weights = [50.0, 1.0, 2.0, 10.0, 50.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2AqQL8hWphaH",
      "metadata": {
        "id": "2AqQL8hWphaH"
      },
      "source": [
        "# Loop through and plot all potential types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7oJgKs8Ejr2d",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oJgKs8Ejr2d",
        "outputId": "5e10d0f9-7ffe-4a81-e7ac-dd7b8678f4c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:825: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)\n",
            "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/20001], Loss: 377.040741\n"
          ]
        }
      ],
      "source": [
        "potential_types = ['gaussian', 'periodic']\n",
        "\n",
        "# Loop through each potential type\n",
        "for potential_type in potential_types:\n",
        "\n",
        "    # Train and save models and loss history for different interaction strengths\n",
        "    models = []\n",
        "    loss_histories = []\n",
        "    for eta in etas:\n",
        "        model_save_path = f\"trained_model_eta_{eta}.pth\"\n",
        "        model, loss_history = train_and_save_pinn(X, N_u=N_u, N_f=N_f, layers=layers, eta=eta, epochs=epochs, lb=lb, ub=ub,\n",
        "                                                  weights=weights, model_save_path=model_save_path, potential_type=potential_type)\n",
        "        models.append(model)\n",
        "        loss_histories.append(loss_history)\n",
        "\n",
        "    # Predict and plot the solutions for all models\n",
        "    predict_and_plot(models, etas, X_test, save_path='plots/predicted_solutions_{potential_type}.png', potential_type=potential_type)\n",
        "\n",
        "    # Plot the loss history for all etas\n",
        "    plot_loss_history(loss_histories, etas, save_path='plots/loss_history_{potential_type}.png', potential_type=potential_type)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}